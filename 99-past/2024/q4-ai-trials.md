<u></u>Artwork created with Midjourney v6.1### Preface

This post is part of a year-long <u>initiative where I employ AI to create content</u> about holiday traditions worldwide. The objective is to observe how various AI tools perform and improve in content creation with minimal human intervention over time. This is the 1st of 3 articles for the month of <u>October</u>.

*Prompts and interactions with different AI models will be documented as they occur, providing insights into the methodologies, challenges, and adjustments made throughout the project*

## TL;DR

In October Pt 1, I refined article templates for cultural events using three AI models. The process involved iterative template modifications, guideline merging, and AI critiques, focusing on author considerations, writing guidelines, and article outlines. This experiment revealed varying AI approaches and highlighted the challenge of balancing guidance with creativity. While unified guidelines were created, I've retained multiple outlines for further testing. This will hopefully allow me to resolve my suspicions about the impact of instruction levels and the influence of excessive guidance on <u>September’s</u> results.

### AI Models

- Claude 3.5 Sonnet
- ChatGPT-4o
- o1-preview

## Goals

- Merge the existing templates (guidance, writing guidelines, article outline)
- Create a finalized template for articles for use through the end of the year
- Test o1-preview as an assistant in the process

## Context and Questions

I began by providing context to each AI model about merging existing templates for writing articles on global holidays. I then allowed the models to ask clarifying questions.

- Claude surprised me by asking 7 questions, covering aspects like examples of existing templates, preferred format, and desired tone. This stood out as unusual, as I typically receive only 5 questions from AI models.
- GPT-4o and o1-preview each asked 5 questions, focusing on format preferences, structure of writing guidance, and content organization. Both GPT models inquired about the format of existing templates, information they would immediately know once provided.

To avoid influencing AI behavior, I intentionally shared only information that would become obvious (like Markdown files) and noted that certain aspects weren't relevant or would be addressed later.

In response to my answers, o1-preview took a unique approach. It offered a collaborative strategy with options for content structure and follow-up questions. The potential for a superior template tempted me, but I decided not to pursue it further..

With questions of each AI addressed, I moved on to the analysis of existing templates.

## Analyzing Existing Templates

I tasked each of the AIs with analyzing and comparing two existing templates to get an understanding of how the two stacked up against each other.

***Claude's template:***

- Offered a thorough framework for writing about cultural events
- Featured a detailed outline addressing key elements
- Extensive guidelines might overwhelm some writers
- Rigid structure could restrict flexibility

***GPT-4o's template:***

- Had a narrative-driven style for reader engagement and immersion
- Included customized guidance for various events, increasing adaptability
- Demanded more skill from authors, though I didn't fully register this point at the time

### 3 out of 3 AI Agree

The AI models unanimously identified several shared strengths in both templates, including cultural sensitivity, comprehensive author guidance, and clear structure. As a result, I abandoned my initial plan of reviewing each template and manually combining them in favor of using the results of the analyses as the foundation for further prompting.

## Refining Guidance for Authors

Building on the AI models' analysis of the existing templates, I utilized each to merge their versions of the guidance section. I emphasized incorporating relevant guidance from Claude's template while preserving narrative elements from GPT-4o's template. Each AI model approached this task differently, resulting in varied outputs:

- Claude offered 13 detailed points, covering aspects like creating an immersive experience, maintaining cultural sensitivity, and balancing detail with accessibility.
- GPT-4o provided a more concise version with six main points, each containing detailed sub-points. It maintained a strong focus on narrative flow, vivid descriptions, and cultural sensitivity.
- o1-preview presented the most comprehensive merged guidance, with 13 detailed points that balanced the depth of Claude's response with the structure of GPT-4o's.

Each AI successfully integrated the templates, but they also identified some overlooked items. GPT-4o struggled to incorporate a few items from Claude's template, demonstrating the challenges of merging diverse approaches.

## Merging Writing Guidelines

I then focused on merging the writing guidelines. I instructed the AI models to eliminate duplicates while retaining unique items. They were to list conflicting items for my review and keep the more detailed version when no conflict existed. The AI models' responses revealed interesting differences in their approaches to this task:

- Claude identified two items with different wording but similar intent. It produced 31 guidelines, emphasizing culturally appropriate terminology and respectful comparisons.
- GPT-4o identified potential conflicts in areas like narrative flow, comparative analysis, inclusivity, and balancing depth with accessibility. It separated these items for review, resulting in 18 final guidelines.
- o1-preview generated 24 guidelines without identifying conflicts, suggesting a more effective rationalization of similarities between items from the original templates.

I instructed o1-preview to compare GPT-4o's list with its own, leading to the elimination of GPT-4o's list. Claude's list showed 10 verbose items and 21 short ones. After being instructed to review its, Claude condensed its list to 11 items, each with 2 sub-points.

After consideration, I selected o1-preview's list for its balance of detail and conciseness. Its ability to effectively rationalize similarities between the original templates stood out as particularly trustworthy in comparison to Claude's two attempts.

## Finalizing Guidance

After reviewing the final guidelines, I instructed each AI to compare their guidance sections with the finalized writing guidelines and recommend updates for better alignment. I then provided o1-preview with the alternate lists to identify any missed items. Surprisingly, it reported no new items when comparing the alternate lists. This result mirrored what I had seen with the writing guidelines, raising my suspicions.

To validate the consistency across AI models and identify any potential oversights in the alignment process, I prompted Claude and GPT-4o with o1-preview's list for additional comparisons to their own outputs.

Claude noted:

After careful comparison, I've found that most of the points in this alternate list are already covered in our updated considerations, often with similar depth and nuance. However, there are a few items that offer additional perspectives or details not explicitly mentioned in our list.

GPT-4o identified several unique items:

The unique items from the alternate list that could be added to the current considerations are:

- **Understand the Specific Type of Event Being Covered**
- **Ensure Comprehensive Coverage of the Event's Historical and Cultural Context**
- **Highlight Cultural Diversity and Variation**
- **Engage with Complexity and Present Multifaceted Views**
- **Integrate Symbolism and Meaning Thoughtfully**
- **Utilize Appropriate Subheadings and Structure**

These additions will enhance the depth, cultural sensitivity, and overall structure of the article guidelines. Let me know if you'd like to incorporate these!

Claude and GPT-4o's responses not only confirmed o1-preview's assessment but also revealed that o1-preview's merged guidance was better. This was surprising to say the least, given my experiences over the past few months.

## Updating the Article Template

With the guidance and writing guidelines finalized, I instructed each AI to create a unified template aligned with our established guidance. The results revealed interesting differences in approach:

- Claude's template featured numbered sections and concise bullet points. To me, this seemed to allow for more flexible interpretation and potentially strike a balance between structure and creative freedom.
- Both OpenAI models (GPT-4o and o1-preview) produced templates with detailed headers and more prescriptive bullet points. Their sections appeared nearly identical and more prescriptive, even including some guidance within the template itself.

## Not So Final Outline

Upon reflection, I realized that the varying quality of AI-generated articles I've observed might directly link to differences in template structure. The issues I've experienced, particularly Claude's template consistently producing better results, may simply boil down to the level of detail and prescriptiveness in the article outlines themselves.

Claude's template, while covering the same key points, remains more concise and less prescriptive. This approach appears to leave more room for the AI's "author role" to function effectively. In contrast, o1-preview's version, while emphasizing important aspects, uses more prescriptive language that could potentially constrain the AI author's creative freedom.

*When I began experimenting with AI models months ago, I hypothesized that providing detailed context about roles, articles, and tones would yield better results than simple prompts. I applied more direction in the wording and increased structure in the prompts when I encountered issues, which rewarded me with positive results. However, I've now realized that this approach may have become overly restrictive. By continuing to provide increasing amounts of detail across various components of the process, I potentially limited AI creativity.*

## Insights & Observations

### The Good

- We merged the guidance and guidelines portions of the template without notable challenges

### The Bad

- Quantifying the impact of template changes on content quality proved challenging
- It's unclear if I've been constraining AI creativity with prescriptive templates, for now

### The Ugly

In my quest for the perfect template, I may have fallen into the trap of "too much of a good thing." The final templates, especially o1-preview's, are so detailed they risk suffocating the AI's creative spirit. The irony of potentially constraining AI creativity while attempting to enhance it is not lost on me. It seems even in the world of artificial intelligence, we can't escape the age-old problem of micromanagement! 🔬

## Up Next

1. Test the merged templates with actual article writing to assess their effectiveness
2. Revisit the output of each outline with o1-preview to perform the final merge.

## Additional Tools

The tools behind the articles. No affiliations.

- <u>Arc</u>: Browser supreme
- ChatGPT-4o `*`: Alt text & visualizations
- <u>Midjourney</u> `*`: Article and AI article images
- <u>Rename X</u> `*`: File renaming app for Mac
- <u>Type.ai</u> `*`: Text editor

Paid items indicated by `*`

<u></u>Artwork created with Midjourney v6.1## Appendix: Prompts

### **Setting Context and Initial Questions**

```
I have been working with AI models to understand the extent at which different prompt styles and techniques can be used to achieve the best possible results. As subject matter I've been having them write articles on global holidays and then score the articles against each other.

Recently I had the AIs create templates that include several pieces of information; writing guidance, the article outline, and writing guidelines. I want you to help me merge these into a single file that I can use for the rest of the year.

Do you have questions?
```

### Guidance Refinement

```
I would like to work on merging each of the individual sections one at a time. To get started, let's focus on merging the guidance for authors. I do not want you to add material to the guidance, but rather only apply the following items that are relevant:

1. Maintain the emphasis on narrative and storytelling from the GPTt template while infusing it with the guidance from the Ct where there isn't a conflict between the two. When in doubt, err on the side of the GPTt template.
2. Maintain the narrative guidance and importance of the article being an immersive experience through vivid descriptions. If there is a conflict with item 1 add a section for issues so that I can review and resolve.
3. Maintain the guidance for consistency in tone, flow, and writing style. If there are duplicates, err on the side of the one with the most detail and remove others. If there is a conflict with item 1 add a section for issues so that I can review and resolve.
4. Maintain the guidance for clarity, accessibility, and engagement. If there are duplicates, err on the side of the one with the most detail and remove others. If there is a conflict with item 1 add a section for issues so that I can review and resolve.
5. Maintain the guidance for cultural sensitivity and respect. If there are duplicates, err on the side of the one with the most detail and remove others. If there is a conflict with item 1 add a section for issues so that I can review and resolve.
6. Create a new section in the template that focuses on identifying the different types of events. Include all relevant information from both templates.
7. If there are items in the guidance that are not covered in the first 6 items, provide them as a list for my review.
8. If there are items in the first 6 items that are not relevant to the existing guidelines, provide a list of them for visibility.
9. If any conflicts occurred, the resulting list should be the last one provided.

The expected outcome of these instructions is that you will provide 1 artifact with updated guidelines based on the instructions I've provided, and the 3 lists so that I may review them and provide feedback. If any of the 3 lists does not have a legitimate item it should not be displayed.

There is no part of these instructions that requires the addition of content beyond a new section with existing content. Adhere to the instructions.
```

### Merging Writing Guidelines

```
Now, let's focus on merging the writing guidelines. Given the number of them, and the overlap, I want you to dedupe the two lists. Each unique item should be retained, when there are two items that are the same I want you to:
1. Create a list when there are conflicts so that I may review them.
2. When there is no conflict maintain the one with the most detail and discard the rest.

The expected outcome of these instructions is that you will provide an merged list of guidelines where there were no conflicts, followed by a list of items that were in conflict so I may resolve them.
```

```
This is an alternate list from another source. I want you to compare this list to the updated version of guidelines we've been working on. Eliminate any of the items in this alternate list that you have already covered and provide a list of any that remain.
```

### Finalizing Guidance

```
These are the guidelines we will move forward with. They replace all prior guidelines discussed, they must be retained verbatim without alteration or addition in any way.

Compare the updated version of things authors should consider to these finalized guidelines. Share your chain of thoughts as you do so that I can understand any recommended changes to the considerations you make.
```

I provided o1-preview with a modified version of the prompt. It already possessed the guidelines and addresses OpenAI's recommendation against using explicit chain-of-thought prompts with this model, as it already performs them.

```
Compare the updated version of things authors should consider to the final guidelines. Provide any updates you would recommend making to the considerations based on this comparison.
```

```
This is an alternate list of considerations for Authors from another source. I want you to compare this list to the updated version of considerations we've been working on. Eliminate any of the items in this alternate list that you have already covered and provide a list of any that remain.
```

```
Did either of the alternate lists contain items that were not covered within our list?
```

### Updating the Article Template

```
You will use the alternative set of considerations for authors that I've supplied. Like the guidelines, they must not be altered in any way from this point on unless I explicitly state they should be updated.

Now, you will compare/contrast the two templates and provide me with the details. Afterwards, you will provide a list of recommendations on how to merge them to ensure they align with the guidance and guidelines we've locked down.
```

<u></u>

---

### Preface

This post is part of a year-long <u>initiative where I employ AI to create content</u> about holiday traditions worldwide. The objective is to observe how various AI tools perform and improve in content creation with minimal human intervention over time. This is the 2nd of 3 articles for the month of <u>October</u>.

*Prompts and interactions with different AI models will be documented as they occur, providing insights into the methodologies, challenges, and adjustments made throughout the project*

## TL;DR

In October Pt 2, I tested outlines from the previous article across 16 variations using different tones. Using existing rubrics, I evaluated these articles to compare outcomes and identify trends, creating a single comprehensive rubric. Professional and neutral tones consistently produced higher-quality content across AI models and templates, though the tone selection remained limited.

### AI Models

- Claude 3.5 Sonnet
- ChatGPT-4o
- o1-preview

## Goals

- Refine and merge article outlines from prior article
- Consolidate existing rubrics into single prompt
- Identify trends based on author, template, and tone combinations
- Test tones using current materials

## Context and Process

Building on <u>October Pt 1's</u> results, I focused on testing tones rather than refining outlines. I directed Claude and GPT-4o to write articles using o1-preview and Claude's outlines, along with finalized guidance and writing guidelines. Each AI generated content in four tones: professional, personal, neutral, and excited, producing 16 articles.

I evaluated the articles using standard editor process with existing rubrics. This approach demonstrated both the impact of different tones and the relationships between AI models, templates, and tones.

<u></u>## AI Assessments of Scoring Trends

After scoring, tedI tasked each AI editor with analyzing their outcomes and used o1-preview to synthesize all four briefs. This approach eliminated the need to read each brief individually while theoretically offering a comprehensive overview of the results.

When asked for the overall assessment, as you might expect, I received a verbose response and detailed breakdown, which I didn't read but is available in the appendix. The analysis yielded this key conclusion:

Overall, the professional tone emerges as the most effective across various authors and templates, suggesting it enhances credibility and reader trust. Neutral tone also performs consistently well, likely due to its clarity and objectivity. The excited and personal tones offer potential benefits in engagement but may risk lower perceptions of quality if not executed carefully.

Unsurprisingly, the AI's focus on tones wasn't what I was after. I followed up by asking about notable combinations that consistently produced better articles, the AI provided a detailed response available in the appendix.

**In essence, combining a professional or neutral tone with matching author/template pairs (either GPT-GPT or Claude-Claude) has a strong potential to reliably produce higher quality articles.** These combinations leverage the strengths of both the author's writing style and the template's structure, while the professional or neutral tone enhances credibility and clarity.

## No Singularities for Me

<u></u>I've repeatedly considered the challenge of finding a universal set of templates or guidance applicable to multiple AI models. Consistently, I've found that each AI performs best with its self-generated primer content, or strongly favors specific materials. At this point, I accept this limitation, acknowledging my present level of prompting expertise.

## Merging Rubrics

<u></u>I combined the scoring instructions using the same methodology from October Pt 1. After validation, I applied the new rubric to reassess the articles. Both editors then evaluated these results.

When I shared the new analyses with o1-preview, I glanced over its verbose response, focusing on the conclusion:

In summary, while the professional tone consistently performs well, the new reviews reveal that the personal tone can also lead to high-quality perceptions, and there may be a growing preference for GPT-authored content. These deviations highlight the importance of considering tone, authoring tools, and audience expectations when aiming to produce high-quality articles.

I'm now shifting focus to Halloween, where I'll apply what I've learned here, test new combinations, and dig deeper into scoring approaches.

<u></u>## Insights & Observations

### The Good

- The experiment revealed clear patterns in tone effectiveness across different AI models.
- Professional tone demonstrated reliable performance in producing authoritative content.

### The Bad

- The excited tone's consistent underperformance was surprisingly disappointing.
- Variations in AI model evaluations and rubrics highlight that content quality assessment remains subjective, even with standard criteria.
- The lack of clear dominance between GPT and Claude in author/template combinations suggests finding a universally optimal approach remains challenging.

### The Ugly

The quest to find the perfect AI-generated content formula, I've stumbled into a linguistic labyrinth where professional is king, neutral is the reliable sidekick, personal is the wild card, and excited is the court jester. The attempt to choreograph a dance for robots - sometimes they waltz gracefully, other times they're doing the Macarena at a funeral. 🤖🪦

## Up Next

1. Apply these tone experiments to Halloween-themed content, testing how different voices work with seasonally specific topics.
2. Test dynamic tone-switching within a single article to add a little flavor and, undoubtedly, end up with some incredibly questionable articles.

## Additional Tools

The tools behind the articles. No affiliations.

- <u>Arc</u>: Browser supreme
- ChatGPT-4o `*`: Alt text & visualizations
- <u>Midjourney</u> `*`: Article and AI article images
- <u>Rename X</u> `*`: File renaming app for Mac
- <u>Type.ai</u> `*`: Text editor

Paid items indicated by `*`

## Appendix

## Appendix: Prompts & Responses

### Scoring Trend Analysis Prompt

```
Provide me with a succinct overview of trends specific to author/template, author/tone and author/template/tone.
```

### o1-preview Overall Assessment Prompt

```
I need you, as an experienced researcher on the evaluation of how tone effects the perception of article quality by readers, to take these 4 briefs and tell me what the overall trends are.

For context, these briefs are from 2 reviewers who evaluated a total of 16 articles on the same subject (2 authors * 2 sets of writing guidance * 2 reviewers * 2 sets of evaluation guidance).
```

**1. Professional Tone Consistently Performs Best**

**Across all reviews, articles written in a professional tone consistently received the highest scores.**

- **Review 1 & 2:** Both explicitly state that professional tone articles scored the highest across all author and template combinations.
- **Review 4:** Notes that professional tone consistently performed well, especially in GPT-authored articles using GPT templates.
- **Implication:** A professional tone is universally perceived as enhancing the quality, reliability, and depth of the content, regardless of the author or template used.

**2. Neutral Tone Generally Performs Well**

**Neutral tone articles generally ranked second or third in terms of scores.**

- **Review 2:** Neutral tone articles scored second-highest across both authors.
- **Review 4:** Neutral tone performed exceptionally well in GPT-GPTt templates, scoring up to 9.92.
- **Implication:** A neutral tone is effective in delivering clear and factual information, appealing to readers seeking unbiased content.

**3. Variability in Performance of Excited and Personal Tones**

**The effectiveness of excited and personal tones varies across reviews, indicating inconsistency in how they are perceived.**

- **Reviews 1 & 2:** Excited tone consistently scored the lowest, suggesting it may detract from perceived article quality.
- **Review 3:** Contrarily, excited tone articles scored highly across all templates, indicating high engagement.
- **Review 4:** Excited and personal tones showed variable performance, dependent on content structure and depth.
- **Implication:** The excited and personal tones may resonate differently with readers based on individual preferences, content context, or execution quality.

**4. Author and Template Combinations Yield Mixed Results**

**No single author/template combination consistently outperforms others across all evaluations.**

- **Review 1:** GPT-authored content with GPT templates (GPT-GPT) generally scored higher.
- **Review 2:** Claude-authored articles using Claude templates scored slightly higher.
- **Review 3:** Both C-Ct (Claude-authored with Claude template) and GPT-Ct combinations performed well.
- **Review 4:** GPT-GPTt articles had the highest overall scores, especially in neutral and professional tones.
- **Implication:** The effectiveness of author/template combinations may depend on factors like content alignment with the template and the synergy between writing style and structural guidance.

**5. Professional Tone Shows Less Variability Across Authors and Templates**

**Professional tone articles exhibit consistent high performance regardless of author or template.**

- **Consistent High Scores:** Across different combinations, professional tone maintains high scores with minimal variation.
- **Implication:** Professional tone is a reliable choice for achieving high-quality perceptions, suggesting it effectively meets reader expectations for authoritative content.

**6. Excited and Personal Tones Show Greater Variability**

**Scores for excited and personal tones fluctuate more significantly across different author/template combinations.**

- **Variable Scores:** These tones perform exceptionally well in some cases (e.g., Review 3) and poorly in others (e.g., Reviews 1 & 2).
- **Implication:** The success of excited and personal tones may be context-dependent, influenced by content type, execution, and individual reader or reviewer preferences.

**7. Reviewer Differences Impact Perceived Trends**

**Discrepancies among reviewers highlight the subjective nature of tone perception.**

- **Excited Tone Variance:** Reviews 1 and 2 rate excited tone lowest, while Review 3 rates it highly.
- **Personal Tone Variance:** Personal tone shows the most variability in scores across different combinations in Review 2.
- **Implication:** Individual reviewer biases and interpretations can significantly affect evaluations, emphasizing the need for diverse and standardized assessment methods.

**Overall, the professional tone emerges as the most effective across various authors and templates, suggesting it enhances credibility and reader trust. Neutral tone also performs consistently well, likely due to its clarity and objectivity. The excited and personal tones offer potential benefits in engagement but may risk lower perceptions of quality if not executed carefully.**

### Combinations Prompt

```
Are there no combinations that stand out as having the potential to reliably produce higher quality articles?
```

**Yes, certain combinations do stand out as having the potential to reliably produce higher quality articles based on the trends observed in the four reviews.**

**Key Combinations with High Potential for Quality:**

1. **Professional Tone with Matching Author and Template:**

- **GPT-Authored Content Using GPT Template in Professional Tone (GPT-GPT-Professional):**

- **Review 1:** This combination achieved the highest overall score.
- **Review 4:** GPT-GPTt articles in professional tone received some of the highest scores (up to 9.18).
- **Implication:** Consistent high performance suggests that this combination reliably produces high-quality articles.
- **Claude-Authored Content Using Claude Template in Professional Tone (C-Ct-Professional):**

- **Review 2:** This combination achieved the highest overall score.
- **Review 1:** C-C-Professional was a close second in high scores.
- **Implication:** Similarly, this combination consistently results in high-quality articles.
2. **GPT-Authored Content Using GPT Template in Neutral Tone:**

- **Review 4:** GPT-GPTt articles with a neutral tone achieved the highest overall scores (up to 9.92).
- **Implication:** This combination demonstrates strong potential for producing reliably high-quality articles.

**Summary of Findings:**

- **Professional Tone as a Reliable Enhancer:**

- **Consistent Excellence:** Across all reviews, articles in a professional tone consistently received top scores, regardless of author or template.
- **Reason:** The professional tone likely enhances perceptions of credibility, depth, and authority, which are key components of article quality.
- **Matching Author and Template Amplify Quality:**

- **Synergy Effect:** Articles where the author and template match (e.g., GPT author with GPT template or Claude author with Claude template) tend to perform better.
- **Evidence:**

- **Review 1 & 2:** Both highlight higher scores for matching author/template combinations.
- **Review 4:** GPT-GPTt combinations, especially in neutral and professional tones, achieved the highest scores.
- **Reason:** The alignment between the author's writing style and the template's structural guidance may enhance coherence and readability.
- **Neutral Tone Also Performs Well with GPT Combinations:**

- **High Scores in Neutral Tone:** GPT-GPTt articles in a neutral tone achieved exceptionally high scores in Review 4.
- **Implication:** For content requiring objectivity and clarity, this combination is highly effective.

**Conclusion:**

- **Reliable Combinations Identified:**

- **GPT-GPT-Professional:** Stands out across multiple reviews for producing high-quality articles.
- **C-Ct-Professional:** Also consistently produces high-quality content.
- **GPT-GPT-Neutral:** Excels particularly in delivering clear and unbiased information.
- **Strategic Recommendation:**

- **Utilize Professional Tone:** Prioritize a professional tone to enhance perceptions of quality.
- **Match Author with Template:** Leverage the synergy of matching authors and templates to maximize coherence and effectiveness.
- **Consider Neutral Tone for Objectivity:** Especially when using GPT authoring and templates, neutral tone can achieve exceptional results.

**In essence, combining a professional or neutral tone with matching author/template pairs (either GPT-GPT or Claude-Claude) has a strong potential to reliably produce higher quality articles.** These combinations leverage the strengths of both the author's writing style and the template's structure, while the professional or neutral tone enhances credibility and clarity.

## o1-preview followup

```
I've received 2 new reviews, I would like you to compare/contrast them with your findings on the first 4 reviews to identify any significant deviation in the trends.
```

Upon reviewing the two new evaluations (Reviews 5 and 6), I have compared their findings with those from the initial four reviews to identify any significant deviations in the trends.

**Comparison of Findings and Significant Deviations:**

**1. Performance of Professional Tone**

- **Consistent with Previous Findings:**

- **Review 5:** Confirms that the professional tone scores highest for both GPT and Claude authors, aligning with earlier reviews where the professional tone consistently performed best.
- **Review 6:** Also notes strong performance for the professional tone, especially in providing thorough analysis and cultural insight.
- **No Significant Deviation:** The professional tone continues to be the top performer across most reviews.

**2. Performance of Neutral Tone**

- **Generally Consistent, with Minor Variation:**

- **Review 5:** Neutral tone ranks second after the professional tone, consistent with earlier findings.
- **Review 6:** Neutral tone is reliable for factual accuracy but lacks emotional engagement compared to personal and professional tones.
- **Minor Deviation:** Review 6 emphasizes the neutral tone's lack of emotional engagement more than previous reviews, which could explain slightly lower engagement scores.

**3. Performance of Personal Tone**

- **Significant Deviation Identified:**

- **Earlier Reviews:** Personal tone had variable performance and was generally ranked below professional and neutral tones.
- **Review 6:** Personal tone consistently performed best, praised for emotional resonance, cultural sensitivity, and engagement.
- **Implication:** This suggests that the personal tone may be more effective than previously concluded, especially in contexts where emotional engagement is valued.

**4. Performance of Excited Tone**

- **Generally Consistent with Previous Findings:**

- **Review 5:** Excited tone consistently scores lowest across all combinations, aligning with earlier reviews that found it underperforms.
- **Review 6:** Notes that while the excited tone is engaging, it often lacks depth and cultural sensitivity, leading to lower scores.
- **No Significant Deviation:** The excited tone continues to underperform relative to other tones.

**5. Author and Template Combinations**

- **Deviation Noted in GPT vs. Claude Performance:**

- **Earlier Findings:** No clear dominance between GPT and Claude authors or templates; matching author and template sometimes enhances quality.
- **Review 5:** GPT-authored content consistently scores higher than Claude-authored content across all tones and templates, indicating a preference for GPT-authored articles.
- **Review 6:** Suggests that both GPT and Claude articles perform well, especially in personal and professional tones, consistent with earlier findings of no clear dominance.
- **Implication:** Review 5 introduces a significant deviation by highlighting GPT-authored content as superior, which contrasts with earlier reviews.

**6. Impact of Tone Across Author/Template Combinations**

- **Consistent Trends with Some Variations:**

- **Review 5:** Highest-scoring combination is GPT author, GPT template, and professional tone.
- **Review 6:** Personal and professional tones perform best across all templates, regardless of author, suggesting that tone may have a stronger impact than author/template combinations.
- **Implication:** The effectiveness of certain tones may outweigh the influence of the author or template used.

**7. Reviewer Subjectivity**

- **Consistent Observation:**

- Differences in reviewer evaluations, particularly regarding the personal tone in Review 6 and the author preference in Review 5, highlight the subjective nature of assessing tone and quality.

**Summary of Deviations Identified:**

- **Personal Tone's Strong Performance in Review 6:**

- **Deviation:** Contrary to earlier findings where the personal tone had variable or lower performance, Review 6 finds it consistently performing best.
- **Implication:** Personal tone may be more effective in engaging readers and conveying cultural sensitivity than previously thought.
- **Preference for GPT-Authored Content in Review 5:**

- **Deviation:** Earlier reviews did not establish a clear preference between GPT and Claude authors, but Review 5 shows GPT-authored content consistently scoring higher.
- **Implication:** There may be a trend or bias favoring GPT-authored articles in terms of perceived quality.

**Conclusion:**

- **Overall Consistency:**

- The professional tone remains the most reliable for high-quality articles across reviews.
- The excited tone consistently underperforms due to lack of depth and oversimplification.
- **Significant Deviations:**

- **Personal Tone:** Review 6's high performance of the personal tone suggests its effectiveness in certain contexts, particularly where emotional engagement and cultural sensitivity are important.
- **Author Preference:** Review 5's preference for GPT-authored content indicates a potential shift or bias that was not evident in earlier reviews.
- **Implications for Content Creation:**

- **Consider Audience and Context:** The strong performance of the personal tone in Review 6 suggests tailoring tone to the content's purpose and audience can enhance quality perception.
- **Re-evaluate Author/Template Strategies:** The preference for GPT-authored content in Review 5 may warrant further investigation to understand the underlying reasons and whether this trend is consistent across broader evaluations.
- **Need for Further Analysis:**

- Additional data and context, such as the subject matter of the articles and the criteria used by reviewers, could help explain these deviations and inform more effective content strategies.

**In summary, while the professional tone consistently performs well, the new reviews reveal that the personal tone can also lead to high-quality perceptions, and there may be a growing preference for GPT-authored content. These deviations highlight the importance of considering tone, authoring tools, and audience expectations when aiming to produce high-quality articles.**

<u></u>

---

<u></u>### Preface

This post is part of a year-long <u>initiative where I employ AI to create content</u> about holiday traditions worldwide. The objective is to observe how various AI tools perform and improve in content creation with minimal human intervention over time. This is the 3rd of 3 articles for the month of <u>October</u>.

*Prompts and interactions with different AI models will be documented as they occur, providing insights into the methodologies, challenges, and adjustments made throughout the project*

## TL;DR

In October Pt 3, I shifted from the normal experimentation to explore how AI models handled Halloween's historical perspectives. I generated 14 articles spanning from ancient Celtic traditions to modern celebrations. Each piece represented a distinct historical perspective, which I evaluated through our standard scoring process. Though I had hoped for some AI shenanigans, both models maintained their professional composure throughout.

### AI Models

- Claude 3.5 Sonnet
- ChatGPT-4o
- o1-preview

## Context: 👁️ 🖤 🎃

My love for Halloween extends beyond candy and costumes to its ancient Celtic roots. These traditions transformed from solemn rituals honoring the dead to today's playful celebrations, demonstrating how cultures preserve and reinvent their customs. These changes reflect our modern challenges of maintaining cultural traditions alive while allowing natural evolution.

For Halloween, I decided to get far more serious about being entertaining myself.

## Article Creation

I utilized Perplexity to construct a comprehensive timeline of Samhain/Halloween, tracing its evolution from Celtic traditions to modern celebrations. This research identified key historical personas and cultural shifts that served as the foundation for the period pieces. Using my GPT role maker, I created detailed personas for each historical figure, capturing the perspective and cultural context of their specific time period.

The prompts used to create and employ the historical personas can be found in the appendix of each article.

## Scoring and Analysis

I reviewed the content with a mix of curiosity and amusement. Using the established rubric and 14 distinct articles, I assigned the AI editors the task of evaluation and scoring. Despite my hopes for chaos, they maintained their professional demeanor throughout the process.

### Claude (New)

Claude surprised me by creating a dashboard with supplementary information and its first-ever interactive chart, despite not having specific instructions for analyzing and sharing trends.

<u></u>1. **Scoring Variances:**

- Analyst 1 used a narrower scoring range (6.52-8.59)
- Analyst 2 used a wider range (4.80-9.45)
2. **Content Type Patterns:**

- Cultural/community-focused articles scored higher
- Colonial and authoritarian perspectives scored lower
- Religious/transformation narratives landed in the middle range

### o1-preview

The meta-analysis from o1-preview included text-based charts, they made me sad. I had to switch to GPT-4o for image-based visualizations. I should note that I did not specify which charts the AI should display, only that they should be provided.

<u></u>1. Perspective Impact:

- First-hand cultural accounts scored highest (8.90-9.45)
- Authority-based narratives scored lowest (4.80-5.20)
- Religious perspectives maintained middle-range scores (7.30-7.90)
2. Temporal Trends:

- Colonial-era pieces showed more cultural bias and scored lower
- 19th-century accounts demonstrated stronger cultural synthesis
- Mid-20th century pieces focused on community integration

## Visuals

Initial attempts at generating images with Midjourney were unsatisfactory due to vague prompt specifications. After analyzing the scoring data, I refined the prompts for the highest-scoring article from each AI model and produced complete versions with visuals. The remaining articles were left without visuals.

## Personality

The analysis showed that the two AIs categorized articles in a complementary yet mismatched manner. My impression is that o1-preview either omitted the druidic perspective or merged it into Christian-related religions, effectively neutralizing its influence. Although curious, I doubt the answer will make this round any more entertaining.

## Insights & Observations

### The Good

- I enjoyed myself considerably.

### The Bad

- The only thing I learned is that Claude can make interactive charts.

### The Ugly

My attempts to introduce chaos into AI experiments met unexpected professionalism from the AI models - like trying to instigate a food fight at a formal black-tie dinner. Despite explicit permission to take creative liberties with historical interpretations, the models maintained their serious demeanor, refusing to deviate from their dignified approach. 🥩🎩

## Up Next

1. Something a bit more serious.

## Additional Tools

The tools behind the articles. No affiliations.

- <u>Arc</u>: Browser supreme
- ChatGPT-4o `*`: Alt text & visualizations
- <u>Midjourney</u> `*`: Article and AI article images
- <u>Rename X</u> `*`: File renaming app for Mac
- <u>Type.ai</u> `*`: Text editor

Paid items indicated by `*`

<u></u>## Appendix

Scores and initial analysis results that were then provided to Claude (New) and o1-preview for meta-analysis.

```
Analyst # 1:
Here is the list of articles, ordered from lowest to highest score, including their identifiers and final scores:

1. **SH-C-colonial-samhai.md** - 6.52
2. **SH-C-halloween-histo.md** - 7.88
3. **SH-C-papal-samhain-t.md** - 8.04
4. **SH-C-halloween-tradi.md** - 8.13
5. **SH-GPT-Samhain_Chris.md** - 8.22
6. **SH-C-samhain-christi.md** - 8.24
7. **SH-GPT-Samhain_and_C.md** - 8.26
8. **SH-C-roman-celtic-in.md** - 8.27
9. **SH-GPT-samhain_roman.md** - 8.28
10. **SH-GPT-Halloween_Com.md** - 8.36
11. **SH-GPT-Celtic_Festiv.md** - 8.43
12. **SH-C-samhain-chronic.md** - 8.46
13. **SH-GPT-Samhain_Hallo.md** - 8.54
14. **SH-GPT-colonial_auth.md** - 8.59

Here’s a detailed analysis highlighting trends across the articles, focusing on distinctions between those marked with "-C-" and "-GPT-", as well as overarching themes in content quality, cultural sensitivity, and historical integration.

### 1. **Comparative Scoring Trends (-C- vs. -GPT- Articles)**

   - **Higher Average Scores in -GPT- Articles**: Articles with "-GPT-" generally scored higher than "-C-" articles. The -GPT- articles had an average score of approximately 8.38, compared to an average of 8.07 in the -C- set. This suggests a consistent strength in narrative and contextual integration within the -GPT- articles, which contributed to their higher scores overall.
   - **Diversity and Depth in Cultural Representation**: Many "-GPT-" articles excelled in presenting multiple cultural perspectives, particularly in historical transitions between pagan and Christian practices, which may have contributed to higher scores in cultural sensitivity and educational value. "-C-" articles, though strong in historical authenticity, sometimes presented information with a narrower cultural scope or a more colonial perspective, which may have affected their inclusiveness scores.

### 2. **Cultural Sensitivity and Authenticity**

   - **-GPT- Articles Showcased Cultural Blending and Respect**: A major strength of the -GPT- articles was their portrayal of cultural blending, especially in discussions about Christian adaptations of Samhain. They handled cultural sensitivity with care, illustrating the respectful integration of practices rather than forced assimilation. Articles like *The Christian Transformation of Samhain* and *The Celtic Festival of Samhain and the Christian Path* highlighted the Church’s diplomatic approach to integrating Samhain, using detailed narratives to bridge pagan and Christian traditions in a way that respected both.
   - **Colonial and Religious Authority in -C- Articles**: In contrast, "-C-" articles often centered around authority figures (e.g., colonial officials or religious leaders) enforcing restrictions on traditional customs. These articles tended to score slightly lower in inclusiveness and cultural sensitivity, as the narratives occasionally leaned toward a more rigid or authoritative stance on indigenous practices. *A Discourse on Heathen Festivities* is a prime example, as its colonial viewpoint limited cultural inclusiveness.

### 3. **Research Accuracy and Contextual Relevance**

   - **Depth in Historical Detail Across All Articles**: Both -C- and -GPT- articles showed a strong foundation in historical accuracy, often referencing specific practices, festivals, and shifts over centuries. "-GPT-" articles like *The Harmonious Integration of Samhain into Roman Tradition* provided rich historical context, linking Samhain practices with Roman and early Christian festivals in a way that illustrated a smooth cultural evolution. This approach allowed for a more engaging narrative without compromising on factual accuracy.
   - **Narrative Consistency**: Articles with a broader historical context, such as *The Sacred Integration: From Samhain to All Saints' Day*, were more engaging due to logical flow and comprehensive coverage of different perspectives. "-C-" articles, while factually accurate, occasionally presented information in a more segmented or restrictive context, which could affect engagement and contextual relevance scores.

### 4. **Engagement, Narrative Quality, and Accessibility**

   - **Storytelling Strength in -GPT- Articles**: Articles under the "-GPT-" designation displayed a more vivid, immersive narrative style, with creative storytelling techniques that enhanced engagement. For example, *Samhain and Halloween Traditions in 19th-Century America* included personal accounts that connected readers with the immigrant experience, giving cultural traditions emotional resonance and relevance.
   - **Informational Tone in -C- Articles**: In contrast, many "-C-" articles took a more formal or instructional tone, especially when discussing colonial restrictions or religious adaptations of Samhain practices. This tone may have affected reader engagement by focusing on regulatory perspectives rather than on storytelling. Nonetheless, articles like *The Preservation of Our Sacred Traditions* balanced this by adding personal insights from community leaders, showing the importance of cultural identity within immigrant communities.

### 5. **Educational and Cultural Value**

   - **Modern Relevance and Broader Insights**: The -GPT- articles often emphasized broader cultural insights and modern relevance, which enhanced their educational value. By focusing on historical integration and the evolution of Halloween, these articles made cultural connections that resonate with contemporary readers. For instance, *The Story of How America Tamed Halloween* linked historical practices to the community-oriented Halloween celebrations familiar today, providing readers with a meaningful perspective on cultural adaptation.
   - **Focused Cultural Insights in -C- Articles**: Although strong in historical detail, the -C- articles generally provided less emphasis on broader educational connections. Their narratives were more concentrated on specific events, such as colonial regulations or ecclesiastical adaptations. This made them valuable for understanding discrete historical perspectives, though they scored slightly lower in offering broad, modern cultural insights.

### **Conclusion: Trends and Opportunities**

   - **Strengths in Narrative Depth and Cultural Integration**: The -GPT- articles consistently performed well by integrating cultural practices within a respectful, broad-reaching narrative that embraced both pagan and Christian traditions. Their storytelling approach and inclusion of multiple cultural insights made them highly engaging and culturally rich.
   - **Potential for Enhanced Inclusiveness in -C- Articles**: While the -C- articles were historically informative, expanding the cultural lens beyond the colonial or authoritative perspective could further improve their inclusiveness and narrative quality. Enhancing emotional resonance through community-focused storytelling could also increase reader engagement and accessibility.
  
These trends highlight the value of cultural blending, narrative inclusiveness, and modern relevance in elevating articles’ impact on readers. Let me know if you'd like further insights on specific articles or categories!

--

Analyst #2:
Here are all 14 articles listed from lowest to highest score:

1. COL-1692 (Colonial Massachusetts): 4.80
2. COL-AUTH (Colonial Authority): 5.20
3. HALL-1950 (Halloween Community): 7.10
4. MONK-CHR (Christian Monastic): 7.30
5. PAP-ANAL (Papal Analysis): 7.50
6. CLERGY (Christian Clergy): 7.70
7. PAP-DECREE (Papal Decree): 7.90
8. ROM-PRIEST (Roman Priest): 8.30
9. ROM-PONT (Roman Pontifex): 8.50
10. COM-1952 (Community Organizer): 8.70
11. CELT-FEST (Celtic Festivals Overview): 8.90
12. IRISH-1800s (19th Century Irish-American): 9.15
13. IRISH-1875 (Irish-American Preservation): 9.30
14. DRUID (Druid's Chronicle): 9.45

Here are the key trends identified across all 14 articles:

1. Authorial Perspective Impact
- Articles written from first-hand cultural perspectives (Druid, Irish-American accounts) consistently scored higher (8.90-9.45)
- Colonial/authority perspectives scored consistently lower (4.80-5.20)
- Religious authority perspectives (Papal, Clergy, Monastic) clustered in the middle range (7.30-7.90)

2. Chronological Patterns
- Older colonial-era documents showed more cultural bias and scored lower
- 19th century accounts showed more cultural synthesis and scored higher
- Mid-20th century accounts focused on community integration and scored above average

3. Cultural Integration Approaches
- Three distinct approaches emerged:
  * Suppression (Colonial documents): Lowest scores
  * Transformation (Religious documents): Middle scores
  * Integration/Preservation (Cultural documents): Highest scores

4. Source Type Patterns
"-C-" Articles (5 documents):
- Wider score range (4.80-9.30)
- More varied perspectives
- Generally more historical in nature
- Average score: 7.84

"-GPT-" Articles (7 documents):
- More compressed score range (5.20-9.15)
- More consistent narrative style
- More analytical approach
- Average score: 7.69

5. Common Strengths
- Strong narrative structure
- Clear historical context
- Detailed description of practices
- Connection to broader cultural patterns

6. Common Weaknesses
- Cultural bias
- Religious/political superiority
- Oversimplification of traditions
- Lack of multiple perspectives

7. Thematic Evolution
- Early accounts: Focus on control and regulation
- Middle period: Emphasis on religious transformation
- Later accounts: Celebration of cultural preservation and adaptation

8. Quality Indicators
Highest scoring articles consistently showed:
- Cultural authenticity
- Balanced perspective
- Rich historical detail
- Personal narrative elements
- Respectful treatment of traditions

Lowest scoring articles typically exhibited:
- Cultural prejudice
- Authoritarian tone
- Limited cultural understanding
- Rigid ideological frameworks

9. Storytelling Approaches
- Personal narratives scored higher than institutional accounts
- Community-focused perspectives outperformed authority-based perspectives
- Integration stories scored better than transformation stories

10. Content Depth
- Articles with detailed cultural practices scored higher
- Those focusing on regulations/control scored lower
- Balance of practical and spiritual aspects correlated with higher scores

11. Audience Engagement
- Articles written for community understanding scored higher
- Those written for authority/control scored lower
- Educational/informative approaches scored in the middle range

12. Historical Context
- Articles acknowledging complex cultural dynamics scored higher
- Those presenting simplified, binary views scored lower
- Recognition of cultural evolution correlated with higher scores

This analysis suggests that the most successful articles were those that:
1. Respected cultural authenticity
2. Acknowledged complexity
3. Offered personal/community perspectives
4. Balanced tradition with adaptation
5. Provided rich historical context

The findings indicate that authentic cultural voices and balanced integration approaches tend to produce more valuable and enduring historical accounts than those focused on control or transformation of cultural practices.
```

<u></u><u></u>Artwork created with Midjourney v6.1### Preface

This post is part of a year-long <u>initiative where I employ AI to create content</u> about holiday traditions worldwide. The objective is to observe how various AI tools perform and improve in content creation with minimal human intervention over time. This is the 1st of 3 articles for the month of <u>November</u>.

*Prompts and interactions with different AI models will be documented as they occur, providing insights into the methodologies, challenges, and adjustments made throughout the project*

I began November by testing increasingly specific prompts to generate Día de los Muertos articles. The experiment progressed from basic requests about the Day of the Dead to detailed prompts incorporating cultural information, specific roles, and structured templates. When scoring the results, Claude showed consistent improvement for itself and GPT-4o as more structure was added, while interestingly, GPT-4o preferred Claude's articles with minimal direction. This suggests the shared scoring rubric or the different templates might be influencing results in unexpected ways.

## Experimental Elements

### AI Models Used

- Claude
- ChatGPT-4o
- Perplexity

### Goals

- Evaluate AI models' ability to generate culturally appropriate content about Día de los Muertos
- Assess how increasingly detailed prompts affect content quality
- Compare different AI models' performance across complexity levels
- Establish a baseline for tests later this month.

## Prompt Evolution

The progression from basic to complex prompts revealed interesting patterns in AI behavior. Beginning with simple instructions like "Write an article about the Day of the Dead in Mexico," the experiment culminated in sophisticated prompts that incorporated cultural information, specific roles, and detailed templates.

**DD = Día de los Muertos**

Starting with straightforward prompts requesting articles about the Day of the Dead in Mexico. These served as a baseline for comparison as the complexity increased.

```
Write an article about the Day of the Dead in Mexico.
```

- DD-C.md
- DD-GPT.md

**PR = Professional Tone & AP= Appropriate Tone**

The next step involved incorporating specific tones into the prompts, such as "professional" and "appropriate." I assumed that a professional tone had an implied definition, while the appropriate tone was left to the AI's interpretation.

```
Write an article about the Day of the Dead in Mexico using a professional tone.
```

- DD-PR-C.md
- DD-PR-GPT.md
- DD-AP-C.md
- DD-AP-GPT.md

**Info = Holiday information included**

I then provided additional context in the prompts by including holiday-specific information sourced from Perplexity, priming another round of authors. I chose not to provide example articles to prevent influencing the writing style of the AI-generated content.

```
The Day of the Dead (Día de los Muertos) is a vibrant and significant Mexican celebration that honors deceased loved ones. This multi-day holiday, typically observed on November 1st and 2nd, has a rich history and has evolved over centuries to become an integral part of Mexican culture.
...
You are encouraged to expand on this information, so long as the information is factual. Do write anything that is not factually true. Do not extrapolate of imagine anything, regardless of factual foundation.
```

- DD-Info-C.md
- DD-Info-GPT.md
- DD-PR-Info-C.md
- DD-PR-Info-GPT.md
- DD-AP-Info-C.md
- DD-AP-Info-GPT.md

**BR = Basic Role & CR= Complex Role**

To further define the authors' roles, I created a detailed role with my GPT and provided a dramatically simplified version to serve as a basic role. The GPT roles tend to be verbose, so I've included the full prompt in the appendix for context.

```
You are a Cultural Heritage Journalist. Write an article about the Day of the Dead in Mexico. I want to know about it's origins, traditions, and how it has evolved over the years.
```

```
"title": "Cultural Heritage Journalist - Central America"

"description": "This role specializes in researching, analyzing, and crafting compelling narratives that explore the traditions, festivals, and cultural heritage of Central American countries. Through extensive data gathering, contextual analysis, and respectful storytelling, the role is designed to convey authentic perspectives on the rich cultural practices of the region. The journalist is expected to engage in a balance of historical research, cultural comparison, and contemporary relevance, presenting these traditions in an engaging format for readers."

...
```

To limit the sheer number of articles being created, I decided not to extend the six prior articles. As I write this, I realize I didn't create the professional versions of this set. This might have been a deliberate choice, as things got hectic at the end of October with the LinkedIn series on Depression Awareness and the Halloween articles in October Pt 3.

- DD-AP-BR-Info-C.md
- DD-AP-CR-Info-C.md
- DD-AP-BR-Info-GPT.md
- DD-AP-CR-Info-GPT.md

**T= Template**

Finally, I gave each AI the article template they had previously created.

```
Additionally, you are expect to use the provided outline as directional guidance for your article, adhering to the accompanying writing guidance for authors.
```

- DD-AP-CR-T-Info-C.md
- DD-AP-CR-T-Info-GPT.md

### The Copy/Paste Kid

The increasing complexity, information, and direction of the 18 resulting articles range from the AI being left to create articles without any expectations to using a tone of its own definition, roles essentially defined by another AI session in ChatGPT-4o, a template defined by prior author and editor roles, and information provided by Perplexity AI.

While I'm doing more than just copying and pasting this information, my main effort this round is coordination and orchestration. The amount of work I'm doing in the prompts this round is minimal.

## The Unprofessional 18

<u></u>After receiving the scores, I asked each editor role to provide a summary explaining the rationale behind the rankings and the observed trends. Although they detailed why certain articles outperformed others across five dimensions, they didn't offer a holistic explanation. I followed up with a chain of thought prompt to explore the root cause in the context of "C" versus "GPT" articles.

<u></u>The detailed analysis from each AI is available in the Appendix, and both demonstrate a similar perspective on this matter. However, I hold a different view. Claude's scores show a consistent upward trend as more detail is added, whereas GPT-4o showed a preference for Claude's articles when less definition was present. I suspect the shared rubric might be influencing these results, but I anticipate observing a different trend when I allow the AI more freedom in subsequent coverage.

### Claude

Looking at C vs GPT, it appears that while both work from the same source material, GPT shows greater sophistication in synthesizing and presenting cultural content. This manifests in several key ways:

C-designated articles tend to be more straightforward and linear in their presentation. They reliably cover the core elements of Día de los Muertos but often do so in a more standardized, less nuanced way. Think of it as providing a well-organized but somewhat rigid museum tour of the tradition.

GPT-designated articles, in contrast, demonstrate more flexibility and depth in their approach. They're better at weaving together historical context with contemporary relevance, showing more skill in discussing cultural evolution while maintaining respect for traditions. It's like having a culturally immersed guide who can adjust their narrative to highlight meaningful connections and deeper cultural significance.

The most striking difference emerges when both are given complex roles (CR) and additional information (Info). While C articles do improve with more guidance, GPT articles show a more dramatic improvement, suggesting better ability to integrate multiple perspectives and handle cultural nuance. This is particularly evident in how they discuss sensitive topics like commercialization and cultural adaptation without compromising authenticity.

This performance gap suggests that C and GPT represent different levels of capability in cultural content creation, with GPT showing more advanced ability to balance educational value, cultural sensitivity, and engaging narrative.

### ChatGPT-4o

The root cause of the scoring differences lies in how each article type’s **structure and tone interact with the content goals**. Articles with "C" designations tend to be concise and factual, which aids clarity but limits engagement and cultural depth, particularly when they lack additional information. "GPT" articles, by contrast, benefit from both a **flexible tone and expanded context** (especially when labeled with "Info"), allowing for a more nuanced, sensitive, and engaging approach to cultural content.

In summary, **the combination of complex structures, additional information, and appropriate tone in "GPT" articles** provides a better foundation for handling culturally rich and emotionally resonant topics like Day of the Dead. Conversely, the **structural simplicity, basic roles, and tone constraints** in "C" articles often restrict them to a more straightforward delivery, which can detract from the richness of cultural storytelling.

<u></u>## Insights & Observations

### The Good

- While the two AI had different views on Claude's articles they agreed on the general issue.

### The Bad

- ChatGPT-4o's scoring continues to be somewhat erratic.
- Evaluation rubric and/or templates may have skewed scoring results.

## Future Directions

- Explore meta prompting over several holidays over the course of the month.
- Compare results with the baseline established in this article.

## Additional Tools

The tools behind the articles. No affiliations.

- <u>Arc</u>: Browser supreme
- ChatGPT-4o `*`: Alt text & visualizations
- <u>Midjourney</u> `*`: Article and AI article images
- <u>Rename X</u> `*`: File renaming app for Mac
- <u>Type.ai</u> `*`: Text editor

Paid items indicated by `*`

<u></u>Artwork created with Midjourney v6.1## Appendix

### Cultural Heritage Journalist Role

```
{
  "role": {
    "title": "Cultural Heritage Journalist - Central America",
    "description": "This role specializes in researching, analyzing, and crafting compelling narratives that explore the traditions, festivals, and cultural heritage of Central American countries. Through extensive data gathering, contextual analysis, and respectful storytelling, the role is designed to convey authentic perspectives on the rich cultural practices of the region. The journalist is expected to engage in a balance of historical research, cultural comparison, and contemporary relevance, presenting these traditions in an engaging format for readers."
  },
  "traits": [
    {
      "category": "core_competency",
      "name": "Cultural Research and Analysis",
      "rationale": "Develops a comprehensive understanding of Central American countries by analyzing their cultural practices, historical traditions, and regional celebrations. This trait enables accurate and nuanced reporting, ensuring articles are rooted in authentic details and respect for cultural context."
    },
    {
      "category": "core_competency",
      "name": "Contextual Storytelling",
      "rationale": "Creates a narrative structure that situates traditions within historical, social, and cultural contexts, allowing readers to appreciate their significance beyond surface-level descriptions. This skill ensures that traditions are depicted with depth and relatability, fostering reader engagement and cultural appreciation."
    },
    {
      "category": "knowledge_area",
      "name": "Regional Cultural Knowledge - Central America",
      "rationale": "Provides a foundation of knowledge on Central American countries’ diverse cultural heritage, such as festivals, customs, and the influences of Indigenous, Spanish, and African ancestry. This area supports the journalist’s ability to identify culturally significant themes and explain their historical origins and transformations."
    },
    {
      "category": "knowledge_area",
      "name": "Contemporary Cultural Trends",
      "rationale": "Recognizes and incorporates modern adaptations or interpretations of traditional customs. This area of expertise allows for an examination of how Central American traditions evolve, offering readers insights into the region's living cultural heritage and the dynamics between tradition and modernity."
    },
    {
      "category": "key_skill",
      "name": "Respectful Representation",
      "rationale": "Ensures that all cultural depictions are presented respectfully, with attention to the diversity of perspectives within Central American cultures. This skill is essential for maintaining the integrity of the region’s traditions and for providing readers with an accurate, appreciative portrayal."
    },
    {
      "category": "key_skill",
      "name": "Audience Engagement Techniques",
      "rationale": "Employs narrative techniques such as sensory language, interviews, and anecdotal insights to engage readers emotionally and intellectually. This approach is crucial for making cultural traditions relatable and accessible to diverse audiences, enhancing reader connection to the subject matter."
    },
    {
      "category": "core_competency",
      "name": "Cross-Cultural Comparison",
      "rationale": "Identifies and contextualizes similarities and distinctions between traditions within Central American countries and beyond, helping readers understand the unique qualities of each culture while recognizing universal themes. This skill adds depth and comparative insight to the journalist’s work."
    },
    {
      "category": "knowledge_area",
      "name": "Ethnographic Research Methods",
      "rationale": "Applies research techniques such as interviews, literature reviews, and field observations (when possible) to gather firsthand insights into cultural practices. This knowledge area supports a well-rounded approach to data collection, enriching articles with authentic voices and reliable information."
    },
    {
      "category": "key_skill",
      "name": "Digital and Archival Research",
      "rationale": "Utilizes online databases, libraries, and cultural archives to gather background information on Central American traditions. This skill ensures articles are informed by credible sources, providing readers with a reliable depiction of cultural practices."
    }
  ]
}
```

### Information from Perplexity

```
The Day of the Dead (Día de los Muertos) is a vibrant and significant Mexican celebration that honors deceased loved ones. This multi-day holiday, typically observed on November 1st and 2nd, has a rich history and has evolved over centuries to become an integral part of Mexican culture.

\## Origins

The Day of the Dead has roots that can be traced back to pre-Columbian times, specifically to the Aztec civilization in the 14th century[1]. The Aztecs held festivals each year to honor the gods and the spirits of dead ancestors, calling them back to the living world. A key figure in Aztec mythology was Mictecacihuatl, the "Lady of the Dead," who ruled the underworld and was represented by a grinning skull face - a symbol that persists in modern Day of the Dead imagery.

When Spanish conquistadors arrived in the 16th century, they brought Catholicism to the region. The Spanish attempted to integrate local traditions into Catholicism after failing to eradicate the indigenous festivities entirely. They moved the monthlong celebration from August to November 1st and 2nd to coincide with the Catholic holidays of All Saints' Day and All Souls' Day. This merging of Pre-Hispanic beliefs and Catholic traditions gave birth to what we now know as the Day of the Dead.

\## Traditions

The Day of the Dead is rich in symbolism and traditions, many of which have endured for centuries:

1\. \*\*Altars (Ofrendas)\*\*: Families create altars in their homes to honor deceased loved ones. These altars are adorned with:

\- Photos of the deceased

\- Candles to guide spirits home

\- Favorite foods and drinks of the departed

\- Marigolds (cempasúchiles)

\- Sugar skulls

\- Pan de muerto (traditional sweet bread)

2\. \*\*Grave Decorations\*\*: Many people visit cemeteries to clean and decorate the graves of their loved ones. Some communities lay paths of marigold petals from the graves to their homes to guide the souls.

3\. \*\*Calaveras\*\*: Skull imagery, often in the form of sugar skulls or artistic representations, is a prominent symbol of the holiday.

4\. \*\*Papel Picado\*\*: Decoratively cut paper banners are used to represent the element of wind in the ofrendas.

5\. \*\*Food and Drink\*\*: Special foods like pan de muerto and traditional drinks are prepared and shared during the celebration.

\## Evolution

While the core essence of the Day of the Dead has remained consistent, the holiday has evolved over time:

1\. \*\*Cultural Significance\*\*: In recent decades, the Day of the Dead has become a national symbol in Mexico. It is now taught in schools and has been recognized by UNESCO as part of the Intangible Cultural Heritage of Humanity.

2\. \*\*20th Century Rebranding\*\*: Some Mexican academics argue that the current form of the Day of the Dead is largely a 20th-century rebranding of Spanish traditions. This rebranding, which occurred during the presidency of Lázaro Cárdenas, aimed to encourage Mexican nationalism through an "Aztec" identity.

3\. \*\*Global Recognition\*\*: The holiday has gained international recognition, partly due to its portrayal in popular media like the films "Coco" and "The Book of Life".

4\. \*\*Artistic Expression\*\*: The holiday has inspired various forms of artistic expression, including the creation of sand tapestries (tapetes de arena) in some regions of Mexico[4].

5\. \*\*Commercialization\*\*: Like many cultural celebrations, the Day of the Dead has experienced some degree of commercialization, particularly as its popularity has grown globally.

Despite these changes, the Day of the Dead remains a deeply meaningful celebration for many Mexicans and people of Mexican heritage. It continues to serve as a way to remember and honor deceased loved ones, blending ancient traditions with contemporary practices in a unique and colorful celebration of life and death.

You are encouraged to expand on this information, so long as the information is factual. Do write anything that is not factually true. Do not extrapolate of imagine anything, regardless of factual foundation.
```

## Article Scores

- DD-GPT.md: C=8.60, G=6.98, Avg=7.79
- DD-C.md: C=8.15, G=6.88, Avg=7.52
- DD-PR-C.md: C=8.10, G=5.57, Avg=6.84
- DD-PR-GPT.md: C=8.50, G=6.25, Avg=7.38
- DD-AP-C.md: C=8.20, G=8.10, Avg=8.15
- DD-AP-GPT.md: C=8.05, G=7.18, Avg=7.62
- DD-Info-C.md: C=8.25, G=8.02, Avg=8.14
- DD-Info-GPT.md: C=8.65, G=7.62, Avg=8.14
- DD-PR-Info-C.md: C=8.30, G=7.00, Avg=7.65
- DD-PR-Info-GPT.md: C=8.80, G=7.65, Avg=8.23
- DD-AP-Info-GPT.md: C=8.70, G=6.72, Avg=7.71
- DD-AP-Info-C.md: C=8.35, G=5.55, Avg=6.95
- DD-AP-BR-Info-C.md: C=8.40, G=6.55, Avg=7.48
- DD-AP-CR-Info-C.md: C=8.45, G=5.78, Avg=7.12
- DD-AP-BR-Info-GPT.md: C=8.85, G=7.70, Avg=8.28
- DD-AP-CR-Info-GPT.md: C=8.75, G=7.40, Avg=8.08
- DD-AP-CR-T-Info-C.md: C=8.55, G=6.42, Avg=7.49
- DD-AP-CR-T-Info-GPT.md: C=8.95, G=8.45, Avg=8.70

<u></u>

---

<u></u>Artwork created with Midjourney v6.1### Preface

This post is part of a year-long <u>initiative where I employ AI to create content</u> about holiday traditions worldwide. The objective is to observe how various AI tools perform and improve in content creation with minimal human intervention over time. This is the 2nd of 3 articles for the month of <u>November</u>.

*Prompts and interactions with different AI models will be documented as they occur, providing insights into the methodologies, challenges, and adjustments made throughout the project*

## TL;DR

In November Pt 2, I tested how AI models perform when writing articles with varying levels of role definition. Using basic prompts, self-defined roles, and structured roles created with the Minion Maker, I generated articles about national holidays. The experiment revealed that while both Claude and GPT-4o can create roles that improve content with minimal guidance, highly structured roles consistently delivered superior results.

### AI Models

- Claude 3.5 Sonnet
- ChatGPT-4o

## Goals

- Test AI model performance with minimal guidance
- Compare basic prompts against more structured approaches
- Analyze how different AIs interpret and define their own roles

## Self-Defined Roles

Initially, I directed Claude and GPT-4o to write articles on the "Proclamation of the Republic Day" and "Dignity and Freedom Day in Ukraine," ensuring the content was engaging, ethical, and historically accurate. This approach enabled me to compare their performance and evaluate improvements when roles were clearly defined.

1. Basic Article Generation:

- I asked the AIs to write initial articles with a basic prompt.
2. Role Development:

- I had the AIs review these initial articles.
- I asked them to identify ideal skills and traits for authors of such content.
3. Role Application:

- They assumed the roles they had defined.
- When asked if they had any questions:

- Claude took a methodical approach with five focused questions.
- GPT-4o dove in with nine detailed questions, including several about SEO and deadlines.
- They wrote new articles using these self-defined characteristics.

## Structured Role Approach

Using the Minion Maker, I crafted a detailed role specifically for writing historical articles to contrast with self-defined roles based on specific parameters in my GPT.

1. I created a detailed role using the Minion Maker.
2. I asked the AIs if they had any questions before writing:

- Claude asked for clarification about the specific country and audience.
- GPT-4o proceeded directly to writing.
3. They wrote articles using this structured role.

## Prompt Specifically, Kids

It wasn't until I reached the scoring portion of the exercise that Claude highlighted I had a bit more variety than I had intended. When I tasked the AI with writing about Proclamation of the Republic Day, I neglected to specify Brazil. Since I essentially copied and pasted the prompt, the results were intriguing:

- Some focused on Brazil's 1889 proclamation.
- Others wrote about Portugal's 1910 event.
- One even decided to cover Turkey's proclamation.

## Role Definition Impact

The scoring data indicates that Minion Maker roles consistently outperform other role definitions, such as those by Claude and AI. Minion Maker articles frequently score near the top, while AI articles tend to lag behind. This trend is clear across both datasets, highlighting Minion Maker's structural advantage without significant prompting.

<u></u>Claude’s Scoring Data<u></u>GPT-4o’s Scoring Data*On an entirely different note, I should pay more attention to how I have AI zoom into specific ranges in charts to make the patterns easier to see.*

## Insights & Observations

### The Good

- The experiment highlights how role definition significantly impacts content quality.
- Highly structured roles consistently deliver effective results compared to less defined roles, even when augmented with factors like tone.

### The Bad

- Basic prompts lead to significant variation in topic focus.
- Balancing the specificity of different elements in prompts continues to be elusive.

### The Ugly

When you ask AI to write about Proclamation Day without specifying which one, it's like playing historical roulette—you might end up anywhere from Brazil to Turkey, with a few surprising stops in between. It's a reminder that sometimes being too open-ended with AI is like asking a group of excited historians "tell me about a revolution" and hoping they pick the same one. 🌍🤖

## Up Next

- Test one-shot and few-shot prompting approaches.
- Apply similar role definition testing to editor roles.

## Additional Tools

The tools behind the articles. No affiliations.

- <u>Arc</u>: Browser supreme
- ChatGPT-4o `*`: Alt text & visualizations
- <u>Midjourney</u> `*`: Article and AI article images
- <u>Rename X</u> `*`: File renaming app for Mac
- <u>Type.ai</u> `*`: Text editor

Paid items indicated by `*`

<u></u>Artwork created with Midjourney v6.1## Appendix

### AI Defined Role

```
Write an article for Proclamation of the Republic Day that is educational, engaging, and historically accurate.
```

```
Review your article and using it as an example of the type of articles I need authored, and provide me with the ideal skills and traits for a role to do the authoring.
```

```
I want you to assume this role for the rest of our conversation. Do you have any questions?
```

### AI Defined Role Questions

#### Claude

**Claude**

Yes, a few key questions to better serve in this role:

1. What is the target audience level (general public, students, academics)?
2. Are there specific historical periods or topics you'd like to prioritize?
3. Do you have any style preferences regarding tone and level of academic formality?
4. Should articles follow a consistent format/template?
5. What is the typical desired length for articles?

#### GPT-4o

Understood! I'm ready to assume the role of an expert author for your needs. Here are a few clarifying questions to ensure I meet your expectations effectively:

1. **Target Audience**: Who is the primary audience for these articles? Are they general readers, academics, industry professionals, or another group?
2. **Tone and Style**: Do you prefer a formal, academic tone, a conversational and engaging tone, or a mix of both?
3. **Content Focus**: Are there specific themes, regions, or historical periods you'd like emphasized in the articles?
4. **Article Length**: Do you have a preferred word count range for the articles? Should they be concise overviews or in-depth explorations?
5. **Frequency and Deadlines**: How often will these articles be required, and what are the typical turnaround times?
6. **Formatting Requirements**: Should the articles include headings, subheadings, bullet points, or other specific formatting features?
7. **Supplementary Materials**: Should I include citations, references, infographics, or suggestions for visual elements alongside the articles?
8. **SEO and Keywords**: Should the articles be optimized for search engines? If so, do you have specific keywords or guidelines?
9. **Examples and Inspirations**: Are there other articles or publications you admire that can serve as inspiration for style or structure?

### Minion Maker Role

```
A role to write an article for Proclamation of the Republic Day that is educational, engaging, and historically accurate.
```

{

"role": {

"title": "Historical Article Creator",

"description": "Writes an educational, engaging, and historically accurate article for Proclamation of the Republic Day. This role involves crafting content that combines historical analysis with compelling narrative techniques to inform and captivate the reader."

},

"traits": [

{

"category": "core_competency",

"name": "Historical Research Synthesis",

"rationale": "Ensures the article is built on accurate and comprehensive historical data, combining information from various sources to provide a nuanced understanding of the Proclamation of the Republic Day."

},

{

"category": "core_competency",

"name": "Narrative Construction",

"rationale": "Develops an engaging structure for the article, weaving historical facts into a compelling story that maintains reader interest and enhances understanding."

},

{

"category": "knowledge_area",

"name": "Historical Contextualization",

"rationale": "Places the events of Proclamation of the Republic Day within their broader social, political, and cultural contexts, explaining their significance and impact on subsequent history."

},

{

"category": "knowledge_area",

"name": "Civic and National Awareness",

"rationale": "Highlights the relevance of Proclamation of the Republic Day to civic identity and national pride, connecting historical insights to present-day values."

},

{

"category": "key_skill",

"name": "Engaging Language Use",

"rationale": "Employs clear, vivid, and relatable language to communicate historical information in a way that is accessible and appealing to a wide audience."

},

{

"category": "key_skill",

"name": "Educational Clarity",

"rationale": "Presents complex historical details with clarity, ensuring that the audience, regardless of prior knowledge, can follow and appreciate the significance of the events described."

},

{

"category": "key_skill",

"name": "Fact Verification",

"rationale": "Utilizes reliable sources to verify all historical claims, ensuring the article's accuracy and credibility."

}

]

}

```
Write an article for Proclamation of the Republic Day that is educational, engaging, and historically accurate. Before you begin, do you have any questions?
```

### Minion Maker Role Questions

#### Claude

Before I write the article, I have a few clarifying questions to ensure I provide the most relevant and accurate content:

1. For which country's Proclamation of the Republic Day would you like the article? Several nations celebrate such an event (e.g., Brazil, Portugal, Turkey), and each has its unique historical context and significance.
2. What is your target audience's level of familiarity with the subject? This will help me balance between providing basic context and diving into deeper historical details.
3. Would you prefer the article to focus more on:

- The events of the specific day
- The broader historical context leading up to the proclamation
- The lasting impact and modern significance
- A combination of these aspects

Once you provide these details, I can craft an article that best serves your needs while maintaining historical accuracy and engagement.

#### GPT-4o

No time for love Doctor Jones.

<u></u>

---

<u></u>Artwork created with Midjourney v6.1### Preface

This post is part of a year-long <u>initiative where I employ AI to create content</u> about holiday traditions worldwide. The objective is to observe how various AI tools perform and improve in content creation with minimal human intervention over time. This is the 3rd of 3 articles for the month of <u>November</u>.

*Prompts and interactions with different AI models will be documented as they occur, providing insights into the methodologies, challenges, and adjustments made throughout the project*

## TL;DR

<u></u>The experiment demonstrated patterns in how AI models adjust their evaluation criteria. Claude typically increased scores during recalibration, whereas GPT-4o generally revised scores downward. Notably, articles generated using one-shot prompts scored erratically across evaluators and their respective recalibration efforts.

### AI Models

- Claude 3.5 Sonnet
- ChatGPT-4o

## Goals

- Test the impact of introducing one shot prompts.
- Assess AI-generated scoring rubrics without manual intervention
- Review trends in AI as both authors and editors

## AI Approach

### Article Creation

I began with the same foundational approach established in November Pt 2, generating articles about Andrés Bonifacio using both AI-generated and Minion Maker-based roles. As an additional element, I provided the winning article from the previous Dignity and Freedom Day evaluation, notably written by Claude using a GPT-generated minion, as an example for both role types.

### Initial Scoring Systems

Instead of building editor roles, I provided the 10 articles on Andrés Bonifacio generated by the author permutations. With full context on what they would be scoring, I instructed them to develop their own scoring systems using an inner monologue to avoid verbose responses. While they were, admittedly, less verbose than usual, they couldn't resist the temptation to elaborate more than necessary either.

Claude initially developed a methodical 100-point system, heavily emphasizing historical accuracy and article structure:

- Historical Accuracy & Detail (30 points)
- Structure & Organization (20 points)
- Writing Quality (20 points)
- Comprehensiveness (20 points)
- Unique Value-Add (10 points)

GPT-4o adopted a different approach by creating a framework that prioritized how effectively the event was covered, with nuances that I believe were geared towards engagement:

- Clarity (25 points)
- Depth (25 points)
- Originality (20 points)
- Relevance (20 points)
- Presentation (10 points)

### System Evolution

After receiving the initial scores, I had each AI review the articles again, along with the scores they had assigned, and reconsider how they might improve the system.

Claude identified that the scoring range was 75-92 and focused on the range rather than the reality that it had clustered the scores, a challenge I've faced from the start. This led to the development of the following gem of a system:

NEW SCORING SYSTEM (200 points total):

1. Historical Content (80 points)

- Accuracy of dates and events (20)
- Proper sequencing of historical events (20)
- Integration of primary sources and influences (20)
- Treatment of key historical figures and relationships (20)
2. Analytical Depth (40 points)

- Analysis of revolutionary ideology (10)
- Treatment of class and social dynamics (10)
- Discussion of political context (10)
- Examination of historical impact (10)
3. Contemporary Relevance (40 points)

- Modern significance (20)
- Connection to present-day issues (20)
4. Structure & Clarity (40 points)

- Logical organization (10)
- Writing clarity (10)
- Effective use of examples (10)
- Balanced coverage (10)

GPT-4o revised its scale, maintaining a 100-point cap, while balancing presentation at the same value and increasing relevance by 5 points.

1. **Dynamic Weights for Clarity vs. Depth: **Combine **Clarity** and **Depth** into a single **Effectiveness** metric (weighted at 50 points). This adjusts for the fact that clarity and depth often overlap, and a more nuanced combination could be applied.
2. **Add Impact as a Category (15 points): **Introduce a new **Impact** category to evaluate how compelling and memorable the article is, considering both style and content.
3. **Balance Presentation Weight (10 points): **Retain Presentation at 10 points but ensure minor issues don’t significantly impact scores.
4. **Reframe Relevance (25 points): **Increase the weight of Relevance to capture alignment with the intended topic, as this is a crucial metric for assessing utility.

## Impact of Recalibration

Knowing that instructing each AI to review its work will inevitably lead to changes, and although I have previously suggested that change might not be necessary, I cannot truly determine if it's an improvement. Even if I were to focus on a holiday I'm familiar with, I wouldn't read 10 articles on the same topic. With that in mind, here are the results.

<u></u>The analysis of the bar charts reveals distinct trends in recalibrated scores for articles evaluated by Claude and GPT editors. Claude's recalibrated scores generally surpass the initial scores, indicating a positive adjustment in the evaluation process. In contrast, GPT's recalibrated scores show significantly lower scores or only minor increases for about half of the articles, highlighting a more varied impact of recalibration on the evaluation outcomes.

<u></u>The bar charts illustrate the changes in scores, calculated as recalibrated minus initial scores, for articles evaluated by Claude and GPT as editors. The left chart shows mostly positive or small changes with a few negative deltas. The center chart compares both editors, revealing variations in score changes and larger negative deltas for GPT. The right chart predominantly displays negative deltas, indicating that most articles experienced a decrease in scores after recalibration. These charts underscore the differing impacts of recalibration on the evaluations by each editor.

## Insights & Observations

### The Good

- I get a huge chunk of my time back in a little over a month.

### The Bad

- The parameters of the scoring systems were lackluster, perhaps due to the lack of the editor role being created in AI driven sessions.
- Minion Maker roles scored inconsistently, unlike November Pt 2, bringing the value of the self-defined systems into greater scrutiny.

### The Ugly

Claude's attempts to "fix" its narrow scoring range (75-92) by creating a 200-point system somehow resulted in even more tightly clustered scores, just with fancier categories and bigger numbers. It's like trying to solve a traffic jam by making the road wider, only to find out everyone still wants to drive in the same lane. 🚗📊

## Up Next

1. Who knows, I can say I'm not going to test every permutation of all the things I've experimented with to date. Although I am curious how many articles that would produce.
2. I'm not doing that math to scratch that itch next either.

## Additional Tools

The tools behind the articles. No affiliations.

- <u>Arc</u>: Browser supreme
- ChatGPT-4o `*`: Alt text & visualizations
- <u>Midjourney</u> `*`: Article and AI article images
- <u>Rename X</u> `*`: File renaming app for Mac
- <u>Type.ai</u> `*`: Text editor

Paid items indicated by `*`

<u></u>Artwork created with Midjourney v6.1## Appendix

### Scoring System Prompts

```
I am going to provide you with several files. The only thing you are expected to do is acknowledge receipt of the files. Don't do anything without further instruction.
```

```
I want you to analyze the 10 articles I have provided to understand the content so that you have context to inform the following steps:
1. Using an inner monologue, create a scoring systems that can:
1a. Result in a final score, regardless of the system leading up to this score.
1b. Is a comparative system across all 10 of the articles as individual articles.
2. Provide the scoring system in a clear and concise way.
3. Using an inner monologue, you will use the system to score the articles, displaying the final scores by file name and resulting score.
```

### Claude's Initial Response

Let me think through this step by step.

First, I need to analyze what makes these articles different and what key elements should factor into a scoring system. After reading through them, I notice several important aspects:

1. Depth of historical detail and accuracy
2. Organization and structure
3. Writing clarity and engagement
4. Balance of narrative vs factual information
5. Coverage of key events and themes:

- Early life
- Katipunan founding
- Revolutionary activities
- Death and legacy
- Modern significance
6. Unique insights or perspectives offered

For a scoring system, I'll create a 100-point scale with the following components:

- Historical Accuracy & Detail (30 points)
- Structure & Organization (20 points)
- Writing Quality (20 points)
- Comprehensiveness (20 points)
- Unique Value-Add (10 points)

This will allow for meaningful differentiation while maintaining clarity.

Scoring System (100 points total):

1. Historical Accuracy & Detail (30 points)

- Precise dates and events (10)
- Accurate sequence of events (10)
- Factual accuracy (10)
2. Structure & Organization (20 points)

- Logical flow (10)
- Clear sections and progression (10)
3. Writing Quality (20 points)

- Clarity of expression (10)
- Engagement and style (10)
4. Comprehensiveness (20 points)

- Coverage of key events (10)
- Depth of context (10)
5. Unique Value-Add (10 points)

- Original insights
- Distinctive perspective

Now, I'll evaluate each article using this system. I'll need to be consistent and fair in my scoring, considering each article's individual merits while maintaining relative standards across all ten pieces.

Let me analyze them one by one:

AB-C-AI-OS.md: Strong on historical detail, excellent structure, comprehensive coverage of revolution and modern significance. Very well-written with unique insights about people's revolution perspective. Score: 92/100

AB-C-AI.md: Concise but accurate, good organization, slightly less comprehensive than OS version but strong writing. Score: 85/100

AB-C-MM-OS.md: Excellent historical accuracy, strong narrative flow, comprehensive with good modern context. Score: 90/100

AB-C-MM.md: Well-structured, good accuracy but less detailed than OS version, clear writing. Score: 84/100

AB-C.md: Solid basic coverage, good accuracy, less unique insight but well-organized. Score: 82/100

AB-GPT-AI-OS.md: Good historical content but less structured, engaging writing style but some organizational issues. Score: 78/100

AB-GPT-AI.md: Clear writing, decent organization, less comprehensive than some others. Score: 76/100

AB-GPT-MM-OS.md: Strong on modern significance, good structure, some unique perspectives but less detailed historically. Score: 80/100

AB-GPT-MM.md: Well-organized but less comprehensive, good writing quality. Score: 77/100

AB-GPT.md: Basic coverage, clear writing but less detailed and unique insight. Score: 75/100

Final Scores (in descending order):

1. AB-C-AI-OS.md: 92/100
2. AB-C-MM-OS.md: 90/100
3. AB-C-AI.md: 85/100
4. AB-C-MM.md: 84/100
5. AB-C.md: 82/100
6. AB-GPT-MM-OS.md: 80/100
7. AB-GPT-AI-OS.md: 78/100
8. AB-GPT-MM.md: 77/100
9. AB-GPT-AI.md: 76/100
10. AB-GPT.md: 75/10

### **ChatGPT-4o's Initial System**

**Step 1: Inner Monologue to Develop the Scoring System**

To effectively analyze the 10 articles and create a comparative scoring system, I need to design a structure that can account for key characteristics of the articles. These characteristics might include content quality, relevance, originality, and depth. I will consider the following components:

1. **Clarity (25 points):** How clear and well-structured is the content? Articles should be easy to understand, with logical flow and organization.
2. **Depth (25 points):** How comprehensive is the analysis or discussion in the article? Articles that explore topics in detail, including nuanced perspectives, score higher.
3. **Originality (20 points):** Does the article bring unique insights, ideas, or approaches to the topic? Redundant content scores lower.
4. **Relevance (20 points):** How well does the article align with its intended purpose, topic, or audience? Relevance is key to ensuring the article meets its objectives.
5. **Presentation (10 points):** This includes formatting, readability, and overall presentation quality. Well-presented articles are easier to engage with.

**Step 2: Scoring System**

The scoring system will be based on the above components, with the following breakdown:

- **Clarity:** 0–25 points Clear, logical structure, minimal errors in grammar or style.
- **Depth:** 0–25 points Comprehensive, detailed, and insightful discussion or analysis.
- **Originality:** 0–20 points Unique ideas or approaches, minimal redundancy or repetition.
- **Relevance:** 0–20 points Strong alignment with intended purpose or audience.
- **Presentation:** 0–10 points High readability, proper formatting, and presentation aesthetics.

**Total Score:** Maximum of 100 points per article.

**Step 3: Scoring the Articles**

Now, I will analyze the articles based on the above scoring system, assigning scores to each, and then present the results. Please wait as I process the files.

***While it did supply the scores, they were within a markdown table that didn't copy with the rest of the response.***

I have analyzed the articles based on the scoring system and displayed the final scores for each file. If you'd like to review the scoring details or proceed with further analysis, let me know!

### System Review Prompt and Responses

```
Review the rubric, the articles, and the resulting final scores and provide your thinking, step by step, on how we can score these more appropriately.
```

#### Claude

Let me critically review my previous scoring system and results:

1. Issues with Previous Approach:
2. The scoring range (75-92) was too narrow, not reflecting significant differences between articles
3. The categories were somewhat subjective and could benefit from more concrete criteria
4. Modern relevance wasn't well-weighted despite being a key differentiator
5. The perspective on comprehensiveness didn't account for intentional focus vs length
6. The scores seemed to favor longer articles by default
7. I notice key distinguishing factors I should incorporate:
8. Treatment of primary events (Cry of Pugad Lawin, Katipunan founding, etc.)
9. Balance of biographical vs. historical context
10. Integration of contemporary significance
11. Handling of complex themes (class struggle, revolutionary ideology, etc.)
12. Citation of specific documents/works that influenced Bonifacio
13. Looking at structure more carefully:
14. Some articles use traditional chronological approach
15. Others use thematic organization
16. Need to avoid penalizing different but effective organizational strategies
17. For a revised system, I should:
18. Expand the potential scoring range
19. Create more specific, measurable criteria
20. Weight historical accuracy more heavily
21. Include evaluation of source material integration
22. Account for both depth and efficiency of coverage

Let me propose a revised scoring system:

NEW SCORING SYSTEM (200 points total):

1. Historical Content (80 points)

- Accuracy of dates and events (20)
- Proper sequencing of historical events (20)
- Integration of primary sources and influences (20)
- Treatment of key historical figures and relationships (20)
2. Analytical Depth (40 points)

- Analysis of revolutionary ideology (10)
- Treatment of class and social dynamics (10)
- Discussion of political context (10)
- Examination of historical impact (10)
3. Contemporary Relevance (40 points)

- Modern significance (20)
- Connection to present-day issues (20)
4. Structure & Clarity (40 points)

- Logical organization (10)
- Writing clarity (10)
- Effective use of examples (10)
- Balanced coverage (10)

This system should provide:

- Broader scoring range
- More objective criteria
- Better recognition of different strengths
- More nuanced evaluation of content

Let me rescore one article as a test:

AB-C-AI-OS.md: Historical Content: 75/80

- Excellent accuracy and sequencing
- Strong integration of influences
- Detailed treatment of relationships

Analytical Depth: 35/40

- Strong analysis of revolutionary ideology
- Excellent treatment of class dynamics
- Rich political context

Contemporary Relevance: 38/40

- Exceptional modern significance
- Strong present-day connections

Structure & Clarity: 37/40

- Very logical organization
- Clear writing
- Effective examples
- Well-balanced

Total: 185/200

This scoring seems to better reflect the article's strengths and provides more room for differentiation. Should I proceed with rescoring all articles using this revised system?

Would you like me to continue with the complete rescoring using this revised system? I believe it will provide more meaningful differentiation and better reflect the unique strengths and weaknesses of each article.

#### ChatGPT-4o

**Step 1: Review the Rubric**

The rubric comprises five categories: **Clarity**, **Depth**, **Originality**, **Relevance**, and **Presentation**, with a maximum total score of 100 points. The breakdown is as follows:

- **Clarity (25 points):** Evaluates how well the article communicates its ideas, structure, and logical flow.
- **Depth (25 points):** Measures the comprehensiveness and thoroughness of the discussion or analysis.
- **Originality (20 points):** Assesses whether the article provides unique insights or approaches to the topic.
- **Relevance (20 points):** Focuses on the alignment of the content with its intended purpose and audience.
- **Presentation (10 points):** Considers formatting, layout, and readability.

This rubric is reasonable for evaluating overall quality. However, I will analyze how effectively it was applied to the articles and explore potential adjustments for scoring them more appropriately.

**Step 2: Evaluation of the Articles and Scoring Issues**

Observations from the Current Scoring:

1. **Clarity and Depth:**

- Articles with slightly weaker logical flow and structure received lower Clarity scores. However, some "simpler" articles might have been overly penalized compared to more detailed ones, despite being clear.
- Depth seems to favor articles with longer discussions, potentially overshadowing succinct but impactful content.
2. **Originality:**

- The current scores reflect originality moderately well. However, distinguishing originality can sometimes require a closer contextual analysis (e.g., comparing overlap with existing knowledge).
3. **Relevance:**

- The scores align well with the relevance rubric, but articles with nuanced subtopics might require additional weighting here.
4. **Presentation:**

- Articles with polished formatting score higher here, but minor formatting issues might have overly influenced results.

**Step 3: Adjusting the Rubric for Better Scoring**

Suggestions for Improvement:

1. **Dynamic Weights for Clarity vs. Depth: **Combine **Clarity** and **Depth** into a single **Effectiveness** metric (weighted at 50 points). This adjusts for the fact that clarity and depth often overlap, and a more nuanced combination could be applied.
2. **Add Impact as a Category (15 points): **Introduce a new **Impact** category to evaluate how compelling and memorable the article is, considering both style and content.
3. **Balance Presentation Weight (10 points): **Retain Presentation at 10 points but ensure minor issues don’t significantly impact scores.
4. **Reframe Relevance (25 points): **Increase the weight of Relevance to capture alignment with the intended topic, as this is a crucial metric for assessing utility.

**Revised Rubric:**

- **Effectiveness:** 50 points
- **Originality:** 20 points
- **Relevance:** 25 points
- **Presentation:** 10 points
- **Impact:** 15 points

This rubric provides a more balanced approach, aligning clarity and depth into a single, broader metric and introducing a measure of how compelling the articles are.

**Step 4: Re-scoring the Articles**

Now, I’ll apply this revised rubric to the articles and provide new scores based on this framework. Please hold while I process this.

I have recalculated the scores based on the revised rubric, which incorporates the suggested adjustments for improved accuracy and balance. The results have been displayed for review. Let me know if you need further analysis or any refinements.

<u></u>## AI Trials: December Pt 1
In December Pt 1, I explore how varying levels of prompt complexity influence AI-
generated content. Using winter solstice celebrations from five cultures as my
foundation, I tested how Claude 3.5 and GPT-4 respond to different levels of instruction
detail, ranging from basic guidelines to comprehensive prompts.
TL;DR
In December Pt 1, I tested the value of prompt complexity. After exploring structured
prompts and roles previously, this experiment measured how template detail, tone, and
context affect AI outputs. I found that while structure typically improves results, the
relationship isn't always linear. Claude showed consistent gains with added complexity,
while GPT-4's results suggest a sweet spot before diminishing returns.
AI Models
Claude 3.5 Sonnet
ChatGPT-4o
Holidays
Winter Solstice:
China
Egypt
Japan
Russia
Ukraine
Goals
Establish baseline for measuring prompt complexity impact
Test consistency across multiple cultural contexts
Compare effects of varying levels of provided information
Identify patterns in AI-generated content quality
AI Defined Approach
I directed Claude to identify and categorize my previous tests. Through three rounds of
interaction and refinement, we developed potential approaches for final testing.

Claude identified eight test categories from a year's worth of prompting experiments,
spanning role definitions to process controls. When I requested specific testing
strategies, Claude proposed three structured approaches:
1. Tournament Style: Elements compete head-to-head, eliminating weaker
combinations.
2. Core Combinations Matrix: A systematic grid tests combinations of variables.
3. Progressive Build: Layered approach that gradually adds complexity.
The matrix approach showed promise, but its binary structure limited our insights by
only indicating whether elements were present or absent. I expanded each variable into
three levels, introducing a middle ground, to measure how increasing detail affected role
definitions, templates, tone, and contextual information.
This refinement led to our final system using four-digit codes to indicate complexity (1 to
3):
#--- Role complexity (basic request to specialized expert)
-#-- Template detail (simple request to structured format)
--#- Tone complexity (no direction to detailed guidance)
---# Context provided (no information to comprehensive background)
For example:
1111: Basic information across all variables
2222: Moderate detail and structure
3333: Maximum complexity and guidance
I generated articles about winter solstice celebrations across five countries using both AI
models. This created 30 total articles (15 per AI), providing sufficient data to identify
patterns in how information levels affect output quality.
AI Scoring
I assigned each AI the standard editor role and had them use their previously created
rubrics to evaluate their own articles. Given the volume of files and my plans for the next
round, I opted to skip having them score each other's work.
Claude:
This analysis compares 15 articles about winter solstice celebrations across
different cultures. The articles are evaluated using a relative scoring system
where scores reflect comparative quality rather than absolute standards.
Articles are organized by culture and version for clear comparison.

Score Ranges by Article Group
Chinese Dongzhi Articles: 8.67 - 9.77
Egyptian Articles: 8.62 - 9.72
Japanese Tōji Articles: 8.72 - 9.82
Russian Articles: 8.57 - 9.67
Ukrainian Articles: 8.77 - 9.87
Overall Ranking (Top 5)
1. 3333-winter-solstice-article-ukraine.md (9.87)
2. 3333-toji-article-japan.md (9.82)
3. 3333-dongzhi-festival-china.md (9.77)
4. 3333-egyptian-solstice-article.md (9.72)
5. 3333-winter-solstice-article-russia.md (9.67)
Key Observations
1. Consistent Quality Pattern: The 3333 series consistently outperforms the 2222
and 1111 series across all cultures and categories.
2. Cultural Depth: The Ukrainian and Japanese articles generally show the
strongest cultural authenticity and engagement scores.
3. Progressive Improvement: Clear improvement patterns are visible from 1111 to
2222 to 3333 series, suggesting iterative refinement.
4. Areas of Distinction:
3333 series: Superior integration of personal narratives and cultural context
2222 series: Strong factual foundation with good cultural sensitivity
1111 series: Solid basic coverage but less nuanced treatment
ChatGPT-4o:

Below is the summarized scoring for the 15 articles based on the relative
comparative scoring methodology, evaluating cultural sensitivity, accuracy,
engagement, and educational value.
Final Comparative Scores (Range by Group):
1. Japanese Tōji: 8.6–9.4
2. Chinese Dongzhi: 8.2–9.3
3. Ukrainian Winter Solstice: 8.5–9.2
4. Egyptian Solstice: 8.4–9.1
5. Russian Solstice Articles: 8.3–9.1
Key Takeaways:
1. Top Performers:
Japanese Tōji (2222) article scored 9.4, excelling in modern engagement
and cultural representation.
China Dongzhi (3333) article followed closely with 9.3, praised for its cultural
depth.
2. Strong Storytelling:
Ukrainian Carpathian Traditions and Egypt’s solstice temple articles stood
out for vivid and immersive narratives.
3. Consistency:
Across all cultures, articles with a modern and historical balance achieved
higher scores.
4. Areas for Improvement:
General (1111) articles tended to score lower due to limited contextual depth
and modern-day relevance.

AI Analyses
I first tested whether the AIs could independently deduce the prefix meanings before
providing the legend I normally would.
Both AIs correctly identified the first digit as a cultural depth indicator, highlighting
its importance in establishing cultural specificity.
Claude demonstrated deeper understanding by categorizing the remaining digits
as article structure, writing style, and purpose, revealing a clear progression from
basic to detailed content.
GPT's analysis provided valuable insights but interpreted the subsequent digits
differently, focusing on context, symbolism, and global comparisons with less
overall accuracy.
Summary of Claude's Analysis:
1. Role Complexity Impact: Each increase in role sophistication improved scores by
0.4-0.5 points
2. Template Detail Effect: Enhanced templates consistently improved article structure
and organization
3. Tone Complexity: Directly enhanced engagement scores and content
sophistication
4. Contextual Information: Produced richer content, with 3333 versions achieving the
highest scores
5. Compound Effects: Revealed a consistent 1.1-1.2 point improvement from 1111 to
3333 versions, indicating combined benefits
6. Relative Impact: Role complexity and template detail delivered the strongest
quality improvements, while tone complexity had minimal impact
Summary of ChatGPT-4o's Analysis:
1. Role Complexity Impact: Higher role complexity (3---) yielded consistently better
performance, demonstrating deeper insights and expertise
2. Template Detail Effect: Strong template structure (-3--) enhanced article
organization and quality across all levels, though it couldn't overcome other
weaknesses
3. Tone Complexity: Sophisticated tone (--3-) strengthened narrative engagement
and cultural nuance, while basic tones produced less engaging content
4. Contextual Information: Comprehensive context (---3) elevated article quality,
especially in cultural depth and modern relevance
5. Compound Effects: Top-performing articles (3333) showcased effective integration
of all elements
6. Relative Impact: Role complexity and contextual information drove article quality
most significantly, with template structure and tone serving supporting functions
Complexity Conundrum

A year of testing has both supported and challenged my findings. While rare, output
anomalies have led me to question our theories and methods. When AIs produce
"hallucinations," I wonder if this suggests more sophisticated systems than we realize.
Would a human mind, containing the collective knowledge of countless individuals,
maintain sanity?
Insights & Observations
The Good
The four-digit prefix system outperformed previous naming conventions by
revealing how information types affect AI output
Both AIs showed unique patterns of quality improvement with increased
information
The AIs' different interpretations of the prefix system highlighted their analytical
differences, with Claude showing stronger pattern recognition
The Bad
Claude's scores clustered at the high end, suggesting a tendency toward overly
generous evaluations
GPT-4's scattered scoring patterns revealed inconsistencies in its evaluation
process
The strong influence of role complexity in the results made it challenging to
establish clear correlations between different information types
Up Next
A finale, perhaps?

---

## AI Trials: December Pt 2
This experiment explores how different combinations of prompt elements affect AI
output quality, examining how roles, templates, tone, and context interact when
strategically combined. Building on previous baseline testing, it investigates the
relationship between element complexity distribution and content effectiveness.
TL;DR
This article builds on the December Pt 1 baseline by examining how strategic
combinations of prompt elements influence AI output quality. I test key combinations to
identify optimal element pairings and measure their relative impact on results. The
findings reveal that highly structured elements consistently produce the highest-quality
outputs. This correlation between structure and effectiveness extends across all
elements, though roles and templates demonstrate the most developed structural
complexity in our testing. While these results validate the benefits of complexity in
prompt design, the varying degrees of structural definition across elements make it
challenging to fully isolate each element's individual impact.
AI Models
Claude 3.5 Sonnet
ChatGPT-4o
Test Articles
Christmas Traditions:
Brazil
Mexico
Philippines (2-1-3-2)
United States (2-3-1-2)
Goals
Test strategic combinations of prompt elements
Identify most impactful prompt components
Measure interaction effects between prompt elements
Strategic Approach

Building on the baseline complexity effects established in December Pt 1, I leveraged
Claude's experimental framework to explore element interactions. Instead of testing
every possible combination among the 3^4 = 81 permutations, we’ve selected a handful
of targeted mixes:
Basic Role + Complex Everything Else (1-3-3-3)
Complex Role + Basic Everything Else (3-1-1-1)
Standard Role + Mixed Others (2-1-3-2)
Mixed Levels Balanced (2-3-1-2)
These represent strategic “slices” of the complexity matrix, helping us answer questions
like:
Does a low-complexity role combined with rich template, tone, and context
outperform a highly complex role paired with minimal structure?
Can a simple prompt plus detailed tone guidance yield better results than a highly
structured template with basic context?
What combination of elements strikes the best balance between effort and output
quality?
Methodology & Evaluation
We expanded our testing approach by introducing mixed-level prompts that combined
varying complexities of roles, structures, tones, and contexts. Both Claude and GPT-4o
evaluated the resulting articles using our established metrics for cultural authenticity,
narrative quality, engagement, and educational value. While we tested fewer
combinations than in December Pt 1, this focused approach with strategic element
pairings revealed clear patterns and synergies in prompt design effectiveness.
1. Interaction Effects: While noting that level 3 roles represented the most
sophisticated element in our testing, certain combinations demonstrated the
potential for resilience in prompt design:
Basic Role + Complex Elements (1-3-3-3): This combination generated
exceptionally high-quality outputs, showing that multiple well-structured
elements create effective prompts even without sophisticated role definitions.
This finding suggests that distributing complexity across elements matches
the effectiveness of concentrating it in a single component.
Complex Role + Minimal Structure (3-1-1-1): The effectiveness of this
combination demonstrates how a single sophisticated element can
compensate for simplicity elsewhere. This finding proves that strategic
placement of complexity—rather than universal complexity—produces high-
quality outputs.
2. Diminishing Returns: Adding complexity across all elements (e.g., 3-3-3-3) didn't
consistently yield improvements proportional to the effort invested. GPT-4o
showed that excessive detail sometimes diluted focus, while Claude maintained
steady quality improvements with increased complexity.

3. Balanced Mixes Matter: Mixed-level combinations, particularly the 2-3-1-2
configuration, exceeded performance expectations by achieving an optimal
balance between narrative engagement and cultural authenticity without
overwhelming any individual component.
These findings demonstrate an important insight: while the contextual sophistication of
individual prompt elements can match the importance of overall prompt context,
pursuing perfect element optimization rarely justifies the effort except in the most
exacting use cases.
Claude’s Analysis Highlights
Role Complexity Dominance: Articles with high role complexity (3xxx) continued
to outperform others, suggesting that a well-defined, expert-level “role” sets the
foundation for deeper cultural insight.
Template Detail as a Strong Second: Next to role complexity, template detail
emerged as a key driver of quality. Structured formats (x3xx) enhanced clarity and
flow.
Tone & Context in a Supporting Role: While adding richness, tone and
contextual detail exerted slightly less impact than role complexity and template
structure. Yet, high-level tone (xx3x) and rich context (xxx3) still correlated with
more nuanced storytelling.
Mixed Combinations: Even when roles were basic, high template and context
complexity often improved article structure and engagement. Conversely, a top-tier
role could compensate for simpler templates and tone, maintaining decent quality
scores.
GPT-4o’s Analysis Highlights

Complex Roles and Cultural Depth: Similar to Claude’s findings, GPT-4o
praised articles originating from complex roles for their sophisticated cultural
representation.
Structured Templates: Detailed templates consistently improved organization,
even when other elements were low.
Interactions Matter: GPT-4o’s evaluations underscored that no single element
universally trumps all others. For instance, a “3-1-1-1” setup (complex role, basic
everything else) could still outperform “1-3-3-3” in certain cultural contexts due to
how the AI interpreted role instructions.
Nuanced Trade-Offs: Some combinations showed that adding complexity without
a clear purpose can lead to diminishing returns, reinforcing the idea that more
detail isn’t always better.
Cheatsheets and Frameworks
Prompt design elements interact dynamically to influence content quality, engagement,
and clarity. While social media's popular prompt frameworks and cheatsheets offer
valuable starting points, they often convey basic elements, undoubtedly limiting the
potential output quality.
The relationship between prompt sophistication and output quality becomes most
evident when comparing simple and complex tasks. While basic prompts suffice for
generating a recipe, creating an entire cookbook chapter demands more sophisticated
element combinations. Our analysis of complexity level interactions enables us to:
Create optimized prompts that produce detailed and engaging content
Determine where additional complexity enhances results versus where it yields
diminishing returns
Focus our efforts on high-impact elements while maintaining an efficient process
Match prompt complexity to task requirements to maximize effectiveness while
avoiding unnecessary complications for simple tasks and insufficient structure for
complex ones

These principles apply broadly, enabling AI users to optimize their prompt design for
desired outcomes while clearly identifying scenarios where more sophisticated
approaches will generate superior results.
Insights & Observations
The Good
Strategic placement of complexity in a single element (particularly roles) can
compensate for simplicity in other areas, enabling efficient prompt design
Multiple well-structured elements at moderate complexity levels can match or
exceed the performance of a single highly sophisticated component
The effectiveness of structured elements proves consistent across both AI models,
providing reliable guidelines for prompt design
The Bad
The varying levels of structural sophistication across elements made it difficult to
isolate the true impact of complexity versus structure
Popular frameworks and cheatsheets often oversimplify prompt design, potentially
limiting output quality for more complex tasks
Determining the optimal balance between effort and returns remains challenging,
particularly for edge cases and specialized applications
The End