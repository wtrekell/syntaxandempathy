{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xsLC0VIODfJi1lA1WO3Zr_nBKrYFf3lK","timestamp":1749916889644}],"authorship_tag":"ABX9TyNAxYchSzHFIS1iFc/MbUXw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_8AIVCB-cME","executionInfo":{"status":"ok","timestamp":1749916490305,"user_tz":420,"elapsed":666,"user":{"displayName":"William Trekell","userId":"06880905822872725426"}},"outputId":"1143f55c-8f08-4c53-9549-05c5f848d2de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounting Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","‚úì Drive mounted successfully\n","üìã Configuration loaded. Ready to process articles.\n"]}],"source":["# =============================================================================\n","# CELL 1: SETUP AND CONFIGURATION\n","# =============================================================================\n","\n","import os\n","import re\n","import json\n","import pandas as pd\n","from pathlib import Path\n","from datetime import datetime\n","from google.colab import drive, files\n","import zipfile\n","\n","# Mount Google Drive (will prompt for authorization)\n","print(\"Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"‚úì Drive mounted successfully\")\n","\n","# Configuration\n","class Config:\n","    \"\"\"Configuration settings for the analysis\"\"\"\n","\n","    # File naming conventions\n","    VERSION_PREFIXES = ['draft-', 'refined-', 'edited-', 'final-']\n","    VERSION_ORDER = {prefix: i for i, prefix in enumerate(VERSION_PREFIXES)}\n","\n","    # Analysis settings\n","    MIN_SENTENCE_LENGTH = 10  # Minimum characters for a sentence\n","    MAX_SENTENCE_LENGTH = 1000  # Maximum characters for a sentence\n","\n","def setup_output_directories(base_path):\n","    \"\"\"Create necessary output directories\"\"\"\n","    # Don't create nested folders - use the base path directly\n","    output_dir = base_path\n","    archive_dir = os.path.join(base_path, 'archive')\n","\n","    os.makedirs(output_dir, exist_ok=True)\n","    os.makedirs(archive_dir, exist_ok=True)\n","\n","    print(f\"‚úì Output directory ready: {output_dir}\")\n","    print(f\"‚úì Archive directory ready: {archive_dir}\")\n","\n","    return output_dir, archive_dir\n","\n","print(\"üìã Configuration loaded. Ready to process articles.\")"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yK1sz0OeHdOP","executionInfo":{"status":"ok","timestamp":1749915964329,"user_tz":420,"elapsed":665,"user":{"displayName":"William Trekell","userId":"06880905822872725426"}},"outputId":"b2a6d03b-d1f2-422d-8ef0-60688ad4fdd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# =============================================================================\n","# CELL 2: DATA INGESTION & VALIDATION (STEP 1)\n","# =============================================================================\n","\n","class ArticleVersions:\n","    \"\"\"Class to handle loading and validating article versions\"\"\"\n","\n","    def __init__(self, article_name, input_path):\n","        self.article_name = article_name\n","        self.input_path = input_path\n","        self.versions = {}\n","        self.metadata = {\n","            'article_name': article_name,\n","            'input_path': input_path,\n","            'processing_timestamp': datetime.now().isoformat(),\n","            'versions_found': [],\n","            'validation_status': 'pending'\n","        }\n","\n","    def load_versions(self):\n","        \"\"\"Load all versions of an article from the specified path\"\"\"\n","        print(f\"\\nüìÅ Loading versions for article: {self.article_name}\")\n","        print(f\"üìÇ Input path: {self.input_path}\")\n","\n","        # Find all files matching the article name pattern\n","        for prefix in Config.VERSION_PREFIXES:\n","            filename = f\"{prefix}{self.article_name}.md\"\n","            filepath = os.path.join(self.input_path, filename)\n","\n","            if os.path.exists(filepath):\n","                try:\n","                    with open(filepath, 'r', encoding='utf-8') as file:\n","                        content = file.read()\n","                        self.versions[prefix.rstrip('-')] = {\n","                            'filename': filename,\n","                            'filepath': filepath,\n","                            'content': content,\n","                            'loaded_at': datetime.now().isoformat(),\n","                            'file_size': len(content)\n","                        }\n","                        print(f\"  ‚úì Loaded: {filename} ({len(content)} characters)\")\n","\n","                except Exception as e:\n","                    print(f\"  ‚úó Error loading {filename}: {str(e)}\")\n","            else:\n","                print(f\"  - Not found: {filename}\")\n","\n","        self.metadata['versions_found'] = list(self.versions.keys())\n","        return self.versions\n","\n","    def validate_version_sequence(self):\n","        \"\"\"Validate that we have the minimum required versions\"\"\"\n","        found_versions = set(self.versions.keys())\n","        required_versions = ['draft', 'final']\n","\n","        # Check for required versions\n","        missing_required = []\n","        for version in required_versions:\n","            if version not in found_versions:\n","                missing_required.append(version)\n","\n","        # Validation results\n","        validation_results = {\n","            'has_draft': 'draft' in found_versions,\n","            'has_final': 'final' in found_versions,\n","            'missing_required': missing_required,\n","            'versions_found': list(found_versions),\n","            'is_valid': len(missing_required) == 0\n","        }\n","\n","        # Update metadata\n","        self.metadata['validation_results'] = validation_results\n","\n","        if validation_results['is_valid']:\n","            self.metadata['validation_status'] = 'passed'\n","            print(f\"‚úì Validation passed: Found {len(found_versions)} versions\")\n","        else:\n","            self.metadata['validation_status'] = 'failed'\n","            print(f\"‚úó Validation failed: Missing required versions\")\n","            print(f\"  Missing: {', '.join(missing_required)}\")\n","\n","        return validation_results\n","\n","    def get_summary(self):\n","        \"\"\"Get a summary of loaded versions\"\"\"\n","        summary = {\n","            'article_name': self.article_name,\n","            'input_path': self.input_path,\n","            'versions_count': len(self.versions),\n","            'validation_status': self.metadata['validation_status'],\n","            'file_sizes': {}\n","        }\n","\n","        for version, data in self.versions.items():\n","            summary['file_sizes'][version] = data['file_size']\n","\n","        return summary\n","\n","print(\"üìñ ArticleVersions class loaded. Ready for data ingestion.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3ky_mO3Fr3D","executionInfo":{"status":"ok","timestamp":1749916495222,"user_tz":420,"elapsed":23,"user":{"displayName":"William Trekell","userId":"06880905822872725426"}},"outputId":"682b314a-9459-43fa-9baf-58e909b38363"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üìñ ArticleVersions class loaded. Ready for data ingestion.\n"]}]},{"cell_type":"code","source":["# =============================================================================\n","# CELL 3: TEXT PREPROCESSING (STEP 2)\n","# =============================================================================\n","\n","class TextPreprocessor:\n","    \"\"\"Class to handle text preprocessing and segmentation\"\"\"\n","\n","    def __init__(self):\n","        self.processed_versions = {}\n","\n","    def clean_markdown(self, text):\n","        \"\"\"Clean markdown formatting while preserving content structure\"\"\"\n","        # Remove markdown formatting but keep the text\n","        patterns = [\n","            (r'^\\s*#{1,6}\\s+', ''),  # Headers\n","            (r'\\*\\*(.*?)\\*\\*', r'\\1'),  # Bold\n","            (r'\\*(.*?)\\*', r'\\1'),  # Italic\n","            (r'`(.*?)`', r'\\1'),  # Inline code\n","            (r'```.*?```', ''),  # Code blocks\n","            (r'!\\[.*?\\]\\(.*?\\)', ''),  # Images\n","            (r'\\[([^\\]]+)\\]\\([^\\)]+\\)', r'\\1'),  # Links\n","            (r'^\\s*[\\*\\-\\+]\\s+', ''),  # Bullet points\n","            (r'^\\s*\\d+\\.\\s+', ''),  # Numbered lists\n","            (r'\\n{3,}', '\\n\\n'),  # Multiple newlines\n","        ]\n","\n","        cleaned_text = text\n","\n","        # Apply patterns that need multiline flag\n","        multiline_patterns = [\n","            (r'^\\s*[\\*\\-\\+]\\s+', ''),  # Bullet points\n","            (r'^\\s*\\d+\\.\\s+', ''),  # Numbered lists\n","        ]\n","\n","        for pattern, replacement in multiline_patterns:\n","            cleaned_text = re.sub(pattern, replacement, cleaned_text, flags=re.MULTILINE)\n","\n","        # Apply regular patterns\n","        regular_patterns = [\n","            (r'^\\s*#{1,6}\\s+', ''),  # Headers\n","            (r'\\*\\*(.*?)\\*\\*', r'\\1'),  # Bold\n","            (r'\\*(.*?)\\*', r'\\1'),  # Italic\n","            (r'`(.*?)`', r'\\1'),  # Inline code\n","            (r'```.*?```', ''),  # Code blocks\n","            (r'!\\[.*?\\]\\(.*?\\)', ''),  # Images\n","            (r'\\[([^\\]]+)\\]\\([^\\)]+\\)', r'\\1'),  # Links\n","            (r'\\n{3,}', '\\n\\n'),  # Multiple newlines\n","        ]\n","\n","        for pattern, replacement in regular_patterns:\n","            cleaned_text = re.sub(pattern, replacement, cleaned_text)\n","\n","        return cleaned_text.strip()\n","\n","    def segment_into_sentences(self, text):\n","        \"\"\"Segment text into sentences with basic filtering\"\"\"\n","        # Simple sentence segmentation (can be enhanced with spaCy later if needed)\n","        sentences = re.split(r'[.!?]+\\s+', text)\n","\n","        # Filter sentences\n","        filtered_sentences = []\n","        for sentence in sentences:\n","            sentence = sentence.strip()\n","            if (Config.MIN_SENTENCE_LENGTH <= len(sentence) <= Config.MAX_SENTENCE_LENGTH\n","                and sentence):\n","                filtered_sentences.append(sentence)\n","\n","        return filtered_sentences\n","\n","    def segment_into_paragraphs(self, text):\n","        \"\"\"Segment text into paragraphs\"\"\"\n","        paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n","        return paragraphs\n","\n","    def process_version(self, version_name, raw_content):\n","        \"\"\"Process a single version of the article\"\"\"\n","        print(f\"  Processing {version_name} version...\")\n","\n","        # Clean the markdown\n","        cleaned_content = self.clean_markdown(raw_content)\n","\n","        # Segment into different units\n","        sentences = self.segment_into_sentences(cleaned_content)\n","        paragraphs = self.segment_into_paragraphs(cleaned_content)\n","\n","        # Calculate basic statistics\n","        stats = {\n","            'character_count': len(cleaned_content),\n","            'word_count': len(cleaned_content.split()),\n","            'sentence_count': len(sentences),\n","            'paragraph_count': len(paragraphs),\n","            'avg_sentence_length': sum(len(s) for s in sentences) / len(sentences) if sentences else 0,\n","            'avg_paragraph_length': sum(len(p) for p in paragraphs) / len(paragraphs) if paragraphs else 0\n","        }\n","\n","        processed_data = {\n","            'version_name': version_name,\n","            'raw_content': raw_content,\n","            'cleaned_content': cleaned_content,\n","            'sentences': sentences,\n","            'paragraphs': paragraphs,\n","            'statistics': stats,\n","            'processed_at': datetime.now().isoformat()\n","        }\n","\n","        self.processed_versions[version_name] = processed_data\n","\n","        print(f\"    ‚úì {stats['sentence_count']} sentences, {stats['paragraph_count']} paragraphs\")\n","        print(f\"    ‚úì {stats['word_count']} words, {stats['character_count']} characters\")\n","\n","        return processed_data\n","\n","    def process_all_versions(self, article_versions):\n","        \"\"\"Process all versions of an article\"\"\"\n","        print(f\"\\nüîÑ Preprocessing text for all versions...\")\n","\n","        for version_name, version_data in article_versions.versions.items():\n","            self.process_version(version_name, version_data['content'])\n","\n","        return self.processed_versions\n","\n","    def get_processing_summary(self):\n","        \"\"\"Get a summary of processing results\"\"\"\n","        summary = {}\n","        for version_name, data in self.processed_versions.items():\n","            summary[version_name] = data['statistics']\n","\n","        return summary\n","\n","print(\"üîß TextPreprocessor class loaded. Ready for text processing.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AhHY2pJqFvOr","executionInfo":{"status":"ok","timestamp":1749916499474,"user_tz":420,"elapsed":35,"user":{"displayName":"William Trekell","userId":"06880905822872725426"}},"outputId":"39006d3b-9bcb-4afc-fec6-05f2531399ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß TextPreprocessor class loaded. Ready for text processing.\n"]}]},{"cell_type":"code","source":["# =============================================================================\n","# CELL 4: EXECUTION FUNCTIONS AND CHECKPOINT MANAGEMENT\n","# =============================================================================\n","\n","def save_checkpoint_data(article_versions, preprocessor, output_path, checkpoint_name=\"steps_1_2\"):\n","    \"\"\"Save checkpoint data for review\"\"\"\n","    checkpoint_data = {\n","        'checkpoint_name': checkpoint_name,\n","        'timestamp': datetime.now().isoformat(),\n","        'article_metadata': article_versions.metadata,\n","        'processing_summary': preprocessor.get_processing_summary(),\n","        'validation_results': article_versions.metadata.get('validation_results', {}),\n","        'article_summary': article_versions.get_summary()\n","    }\n","\n","    # Save to output directory\n","    checkpoint_file = f\"{output_path}/{article_versions.article_name}_checkpoint_{checkpoint_name}.json\"\n","\n","    with open(checkpoint_file, 'w', encoding='utf-8') as f:\n","        json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)\n","\n","    print(f\"\\nüíæ Checkpoint saved: {checkpoint_file}\")\n","    return checkpoint_data\n","\n","def run_steps_1_2(article_name, input_path, base_output_path):\n","    \"\"\"Run steps 1-2 for a given article\"\"\"\n","    print(f\"üöÄ Starting Steps 1-2 for article: {article_name}\")\n","    print(f\"üìÇ Input path: {input_path}\")\n","\n","    # Setup output directories\n","    output_dir, archive_dir = setup_output_directories(base_output_path)\n","\n","    # Step 1: Data Ingestion & Validation\n","    article_versions = ArticleVersions(article_name, input_path)\n","    article_versions.load_versions()\n","    validation_results = article_versions.validate_version_sequence()\n","\n","    if not validation_results['is_valid']:\n","        print(\"‚ùå Cannot proceed: Missing required versions (draft and final)\")\n","        return None, None\n","\n","    # Step 2: Text Preprocessing\n","    preprocessor = TextPreprocessor()\n","    preprocessor.process_all_versions(article_versions)\n","\n","    # Save checkpoint\n","    checkpoint_data = save_checkpoint_data(article_versions, preprocessor, output_dir)\n","\n","    print(f\"\\n‚úÖ Steps 1-2 completed successfully!\")\n","    print(f\"üìä Processing Summary:\")\n","    for version, stats in preprocessor.get_processing_summary().items():\n","        print(f\"  {version}: {stats['word_count']} words, {stats['sentence_count']} sentences\")\n","\n","    return article_versions, preprocessor\n","\n","# Interactive input functions\n","def get_user_inputs():\n","    \"\"\"Get user inputs for processing\"\"\"\n","    print(\"üìù Please provide the following information:\")\n","\n","    article_name = input(\"Enter article name (without .md extension): \").strip()\n","    input_path = input(\"Enter full path to input folder containing markdown files: \").strip()\n","    base_output_path = input(\"Enter full path to base output folder: \").strip()\n","\n","    print(f\"\\nüìã Configuration:\")\n","    print(f\"  Article name: {article_name}\")\n","    print(f\"  Input path: {input_path}\")\n","    print(f\"  Output path: {base_output_path}\")\n","\n","    confirm = input(\"\\nProceed with these settings? (y/n): \").strip().lower()\n","\n","    if confirm == 'y':\n","        return article_name, input_path, base_output_path\n","    else:\n","        print(\"‚ùå Cancelled. Run get_user_inputs() again to restart.\")\n","        return None, None, None\n","\n","def process_article_interactive():\n","    \"\"\"Process an article with interactive inputs\"\"\"\n","    article_name, input_path, base_output_path = get_user_inputs()\n","\n","    if article_name and input_path and base_output_path:\n","        return run_steps_1_2(article_name, input_path, base_output_path)\n","    else:\n","        return None, None\n","\n","print(\"üìã Ready to process your article!\")\n","print(\"Run: article_versions, preprocessor = process_article_interactive()\")\n","print(\"\\nMake sure your markdown files are named:\")\n","print(\"- draft-your-article-name.md\")\n","print(\"- refined-your-article-name.md\")\n","print(\"- edited-your-article-name.md\")\n","print(\"- final-your-article-name.md\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I4bdYVJdFyQD","executionInfo":{"status":"ok","timestamp":1749916505083,"user_tz":420,"elapsed":20,"user":{"displayName":"William Trekell","userId":"06880905822872725426"}},"outputId":"e03d134f-29b4-49bd-99f3-e282352d7ffa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üìã Ready to process your article!\n","Run: article_versions, preprocessor = process_article_interactive()\n","\n","Make sure your markdown files are named:\n","- draft-your-article-name.md\n","- refined-your-article-name.md\n","- edited-your-article-name.md\n","- final-your-article-name.md\n"]}]},{"cell_type":"code","source":["# =============================================================================\n","# CELL 5: SAMPLE DATA CREATOR (FOR TESTING ONLY)\n","# =============================================================================\n","\n","def create_sample_files_for_testing(output_path):\n","    \"\"\"Create sample markdown files for testing (run this once to test)\"\"\"\n","    sample_content = {\n","        'draft-': \"\"\"# Sample Article\n","\n","This is a draft article about artificial intelligence and its impact on society. AI has revolutionized many industries.\n","\n","The technology continues to evolve rapidly. Machine learning algorithms are becoming more sophisticated every day.\n","\n","We must consider the ethical implications of AI development.\"\"\",\n","\n","        'refined-': \"\"\"# Sample Article\n","\n","This is a refined article examining artificial intelligence and its transformative impact on modern society. AI has fundamentally revolutionized numerous industries across the globe.\n","\n","The technology continues to evolve at an unprecedented pace. Advanced machine learning algorithms are becoming increasingly sophisticated with each passing day.\n","\n","We must carefully consider the complex ethical implications of AI development and deployment.\"\"\",\n","\n","        'edited-': \"\"\"# Sample Article\n","\n","This comprehensive article examines artificial intelligence and its transformative impact on modern society. AI has fundamentally revolutionized numerous industries worldwide, reshaping how we work and live.\n","\n","The technology continues to evolve at an unprecedented pace, driven by breakthrough innovations. Advanced machine learning algorithms are becoming increasingly sophisticated, enabling new applications we never thought possible.\n","\n","We must carefully consider the complex ethical implications of AI development and deployment, ensuring responsible innovation for the benefit of humanity.\"\"\",\n","\n","        'final-': \"\"\"# Sample Article\n","\n","This comprehensive article examines artificial intelligence and its transformative impact on modern society. AI has fundamentally revolutionized numerous industries worldwide, reshaping how we work, communicate, and live.\n","\n","The technology continues to evolve at an unprecedented pace, driven by breakthrough innovations in computing power and algorithmic design. Advanced machine learning algorithms are becoming increasingly sophisticated, enabling new applications we never thought possible just a decade ago.\n","\n","We must carefully consider the complex ethical implications of AI development and deployment, ensuring responsible innovation that serves the benefit of all humanity while mitigating potential risks.\"\"\"\n","    }\n","\n","    article_name = \"sample-article\"\n","    os.makedirs(output_path, exist_ok=True)\n","\n","    for prefix, content in sample_content.items():\n","        filename = f\"{prefix}{article_name}.md\"\n","        filepath = os.path.join(output_path, filename)\n","\n","        with open(filepath, 'w', encoding='utf-8') as f:\n","            f.write(content)\n","\n","        print(f\"Created: {filename}\")\n","\n","    return article_name, output_path\n","\n","print(\"\\nüß™ Sample data creator available for testing if needed.\")\n","print(\"To create test files, run:\")\n","print(\"sample_name, sample_path = create_sample_files_for_testing('/your/test/path')\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lipLfDL1F1LD","executionInfo":{"status":"ok","timestamp":1749916170441,"user_tz":420,"elapsed":20,"user":{"displayName":"William Trekell","userId":"06880905822872725426"}},"outputId":"399d6b1b-f7c3-4ff9-d66b-fd33dfc141de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üß™ Sample data creator available for testing.\n","Uncomment and run the following to test with sample data:\n","sample_name, sample_path = create_sample_files_for_testing('/content/drive/MyDrive/test_input')\n","article_versions, preprocessor = run_steps_1_2(sample_name, sample_path, '/content/drive/MyDrive/test_output')\n"]}]},{"cell_type":"code","source":["article_versions, preprocessor = process_article_interactive()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":738},"id":"C-hysVC7J3F0","executionInfo":{"status":"error","timestamp":1749916666787,"user_tz":420,"elapsed":108067,"user":{"displayName":"William Trekell","userId":"06880905822872725426"}},"outputId":"6af37d28-76cd-43fa-b2a8-7bcd1e0f2f48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üìù Please provide the following information:\n","Enter article name (without .md extension): markup-languages\n","Enter full path to input folder containing markdown files: /content/drive/MyDrive/Google Drive/syntaxandempathy/30-articles/ai-vs-human\n","Enter full path to base output folder: /content/drive/MyDrive/Google Drive/syntaxandempathy/30-articles/ai-vs-human/output\n","\n","üìã Configuration:\n","  Article name: markup-languages\n","  Input path: /content/drive/MyDrive/Google Drive/syntaxandempathy/30-articles/ai-vs-human\n","  Output path: /content/drive/MyDrive/Google Drive/syntaxandempathy/30-articles/ai-vs-human/output\n","\n","Proceed with these settings? (y/n): y\n","üöÄ Starting Steps 1-2 for article: markup-languages\n","üìÇ Input path: /content/drive/MyDrive/Google Drive/syntaxandempathy/30-articles/ai-vs-human\n","‚úì Output directory ready: /content/drive/MyDrive/Google Drive/syntaxandempathy/30-articles/ai-vs-human/output/output\n","‚úì Archive directory ready: /content/drive/MyDrive/Google Drive/syntaxandempathy/30-articles/ai-vs-human/output/archive\n","\n","üìÅ Loading versions for article: markup-languages\n","üìÇ Input path: /content/drive/MyDrive/Google Drive/syntaxandempathy/30-articles/ai-vs-human\n","  ‚úì Loaded: draft-markup-languages.md (5667 characters)\n","  ‚úì Loaded: refined-markup-languages.md (7301 characters)\n","  ‚úì Loaded: edited-markup-languages.md (7575 characters)\n","  ‚úì Loaded: final-markup-languages.md (6327 characters)\n","‚úì Validation passed: Found 4 versions\n","\n","üîÑ Preprocessing text for all versions...\n","  Processing draft version...\n"]},{"output_type":"error","ename":"ValueError","evalue":"too many values to unpack (expected 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-2900553146>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marticle_versions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_article_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-3941687529>\u001b[0m in \u001b[0;36mprocess_article_interactive\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marticle_name\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_path\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_output_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_steps_1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_output_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-3941687529>\u001b[0m in \u001b[0;36mrun_steps_1_2\u001b[0;34m(article_name, input_path, base_output_path)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Step 2: Text Preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextPreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_all_versions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_versions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Save checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-4184717035>\u001b[0m in \u001b[0;36mprocess_all_versions\u001b[0;34m(self, article_versions)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mversion_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marticle_versions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-4184717035>\u001b[0m in \u001b[0;36mprocess_version\u001b[0;34m(self, version_name, raw_content)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Clean the markdown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mcleaned_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Segment into different units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-4184717035>\u001b[0m in \u001b[0;36mclean_markdown\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcleaned_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# All except the last one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mcleaned_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcleaned_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}]}]}