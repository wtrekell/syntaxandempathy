<u></u>Artwork created with Midjourney v6.1### Preface

This post is part of a year-long <u>initiative where I employ AI to create content</u> about holiday traditions worldwide. The objective is to observe how various AI tools perform and improve in content creation with minimal human intervention over time. This is the 3rd of 3 articles for the month of <u>November</u>.

*Prompts and interactions with different AI models will be documented as they occur, providing insights into the methodologies, challenges, and adjustments made throughout the project*

## TL;DR

<u></u>The experiment demonstrated patterns in how AI models adjust their evaluation criteria. Claude typically increased scores during recalibration, whereas GPT-4o generally revised scores downward. Notably, articles generated using one-shot prompts scored erratically across evaluators and their respective recalibration efforts.

### AI Models

- Claude 3.5 Sonnet
- ChatGPT-4o

## Goals

- Test the impact of introducing one shot prompts.
- Assess AI-generated scoring rubrics without manual intervention
- Review trends in AI as both authors and editors

## AI Approach

### Article Creation

I began with the same foundational approach established in November Pt 2, generating articles about AndrÃ©s Bonifacio using both AI-generated and Minion Maker-based roles. As an additional element, I provided the winning article from the previous Dignity and Freedom Day evaluation, notably written by Claude using a GPT-generated minion, as an example for both role types.

### Initial Scoring Systems

Instead of building editor roles, I provided the 10 articles on AndrÃ©s Bonifacio generated by the author permutations. With full context on what they would be scoring, I instructed them to develop their own scoring systems using an inner monologue to avoid verbose responses. While they were, admittedly, less verbose than usual, they couldn't resist the temptation to elaborate more than necessary either.

Claude initially developed a methodical 100-point system, heavily emphasizing historical accuracy and article structure:

- Historical Accuracy & Detail (30 points)
- Structure & Organization (20 points)
- Writing Quality (20 points)
- Comprehensiveness (20 points)
- Unique Value-Add (10 points)

GPT-4o adopted a different approach by creating a framework that prioritized how effectively the event was covered, with nuances that I believe were geared towards engagement:

- Clarity (25 points)
- Depth (25 points)
- Originality (20 points)
- Relevance (20 points)
- Presentation (10 points)

### System Evolution

After receiving the initial scores, I had each AI review the articles again, along with the scores they had assigned, and reconsider how they might improve the system.

Claude identified that the scoring range was 75-92 and focused on the range rather than the reality that it had clustered the scores, a challenge I've faced from the start. This led to the development of the following gem of a system:

NEW SCORING SYSTEM (200 points total):

1. Historical Content (80 points)

- Accuracy of dates and events (20)
- Proper sequencing of historical events (20)
- Integration of primary sources and influences (20)
- Treatment of key historical figures and relationships (20)
2. Analytical Depth (40 points)

- Analysis of revolutionary ideology (10)
- Treatment of class and social dynamics (10)
- Discussion of political context (10)
- Examination of historical impact (10)
3. Contemporary Relevance (40 points)

- Modern significance (20)
- Connection to present-day issues (20)
4. Structure & Clarity (40 points)

- Logical organization (10)
- Writing clarity (10)
- Effective use of examples (10)
- Balanced coverage (10)

GPT-4o revised its scale, maintaining a 100-point cap, while balancing presentation at the same value and increasing relevance by 5 points.

1. **Dynamic Weights for Clarity vs. Depth: **Combine **Clarity** and **Depth** into a single **Effectiveness** metric (weighted at 50 points). This adjusts for the fact that clarity and depth often overlap, and a more nuanced combination could be applied.
2. **Add Impact as a Category (15 points): **Introduce a new **Impact** category to evaluate how compelling and memorable the article is, considering both style and content.
3. **Balance Presentation Weight (10 points): **Retain Presentation at 10 points but ensure minor issues donâ€™t significantly impact scores.
4. **Reframe Relevance (25 points): **Increase the weight of Relevance to capture alignment with the intended topic, as this is a crucial metric for assessing utility.

## Impact of Recalibration

Knowing that instructing each AI to review its work will inevitably lead to changes, and although I have previously suggested that change might not be necessary, I cannot truly determine if it's an improvement. Even if I were to focus on a holiday I'm familiar with, I wouldn't read 10 articles on the same topic. With that in mind, here are the results.

<u></u>The analysis of the bar charts reveals distinct trends in recalibrated scores for articles evaluated by Claude and GPT editors. Claude's recalibrated scores generally surpass the initial scores, indicating a positive adjustment in the evaluation process. In contrast, GPT's recalibrated scores show significantly lower scores or only minor increases for about half of the articles, highlighting a more varied impact of recalibration on the evaluation outcomes.

<u></u>The bar charts illustrate the changes in scores, calculated as recalibrated minus initial scores, for articles evaluated by Claude and GPT as editors. The left chart shows mostly positive or small changes with a few negative deltas. The center chart compares both editors, revealing variations in score changes and larger negative deltas for GPT. The right chart predominantly displays negative deltas, indicating that most articles experienced a decrease in scores after recalibration. These charts underscore the differing impacts of recalibration on the evaluations by each editor.

## Insights & Observations

### The Good

- I get a huge chunk of my time back in a little over a month.

### The Bad

- The parameters of the scoring systems were lackluster, perhaps due to the lack of the editor role being created in AI driven sessions.
- Minion Maker roles scored inconsistently, unlike November Pt 2, bringing the value of the self-defined systems into greater scrutiny.

### The Ugly

Claude's attempts to "fix" its narrow scoring range (75-92) by creating a 200-point system somehow resulted in even more tightly clustered scores, just with fancier categories and bigger numbers. It's like trying to solve a traffic jam by making the road wider, only to find out everyone still wants to drive in the same lane. ðŸš—ðŸ“Š

## Up Next

1. Who knows, I can say I'm not going to test every permutation of all the things I've experimented with to date. Although I am curious how many articles that would produce.
2. I'm not doing that math to scratch that itch next either.

## Additional Tools

The tools behind the articles. No affiliations.

- <u>Arc</u>: Browser supreme
- ChatGPT-4o `*`: Alt text & visualizations
- <u>Midjourney</u> `*`: Article and AI article images
- <u>Rename X</u> `*`: File renaming app for Mac
- <u>Type.ai</u> `*`: Text editor

Paid items indicated by `*`

<u></u>Artwork created with Midjourney v6.1## Appendix

### Scoring System Prompts

```
I am going to provide you with several files. The only thing you are expected to do is acknowledge receipt of the files. Don't do anything without further instruction.
```

```
I want you to analyze the 10 articles I have provided to understand the content so that you have context to inform the following steps:
1. Using an inner monologue, create a scoring systems that can:
1a. Result in a final score, regardless of the system leading up to this score.
1b. Is a comparative system across all 10 of the articles as individual articles.
2. Provide the scoring system in a clear and concise way.
3. Using an inner monologue, you will use the system to score the articles, displaying the final scores by file name and resulting score.
```

### Claude's Initial Response

Let me think through this step by step.

First, I need to analyze what makes these articles different and what key elements should factor into a scoring system. After reading through them, I notice several important aspects:

1. Depth of historical detail and accuracy
2. Organization and structure
3. Writing clarity and engagement
4. Balance of narrative vs factual information
5. Coverage of key events and themes:

- Early life
- Katipunan founding
- Revolutionary activities
- Death and legacy
- Modern significance
6. Unique insights or perspectives offered

For a scoring system, I'll create a 100-point scale with the following components:

- Historical Accuracy & Detail (30 points)
- Structure & Organization (20 points)
- Writing Quality (20 points)
- Comprehensiveness (20 points)
- Unique Value-Add (10 points)

This will allow for meaningful differentiation while maintaining clarity.

Scoring System (100 points total):

1. Historical Accuracy & Detail (30 points)

- Precise dates and events (10)
- Accurate sequence of events (10)
- Factual accuracy (10)
2. Structure & Organization (20 points)

- Logical flow (10)
- Clear sections and progression (10)
3. Writing Quality (20 points)

- Clarity of expression (10)
- Engagement and style (10)
4. Comprehensiveness (20 points)

- Coverage of key events (10)
- Depth of context (10)
5. Unique Value-Add (10 points)

- Original insights
- Distinctive perspective

Now, I'll evaluate each article using this system. I'll need to be consistent and fair in my scoring, considering each article's individual merits while maintaining relative standards across all ten pieces.

Let me analyze them one by one:

AB-C-AI-OS.md: Strong on historical detail, excellent structure, comprehensive coverage of revolution and modern significance. Very well-written with unique insights about people's revolution perspective. Score: 92/100

AB-C-AI.md: Concise but accurate, good organization, slightly less comprehensive than OS version but strong writing. Score: 85/100

AB-C-MM-OS.md: Excellent historical accuracy, strong narrative flow, comprehensive with good modern context. Score: 90/100

AB-C-MM.md: Well-structured, good accuracy but less detailed than OS version, clear writing. Score: 84/100

AB-C.md: Solid basic coverage, good accuracy, less unique insight but well-organized. Score: 82/100

AB-GPT-AI-OS.md: Good historical content but less structured, engaging writing style but some organizational issues. Score: 78/100

AB-GPT-AI.md: Clear writing, decent organization, less comprehensive than some others. Score: 76/100

AB-GPT-MM-OS.md: Strong on modern significance, good structure, some unique perspectives but less detailed historically. Score: 80/100

AB-GPT-MM.md: Well-organized but less comprehensive, good writing quality. Score: 77/100

AB-GPT.md: Basic coverage, clear writing but less detailed and unique insight. Score: 75/100

Final Scores (in descending order):

1. AB-C-AI-OS.md: 92/100
2. AB-C-MM-OS.md: 90/100
3. AB-C-AI.md: 85/100
4. AB-C-MM.md: 84/100
5. AB-C.md: 82/100
6. AB-GPT-MM-OS.md: 80/100
7. AB-GPT-AI-OS.md: 78/100
8. AB-GPT-MM.md: 77/100
9. AB-GPT-AI.md: 76/100
10. AB-GPT.md: 75/10

### **ChatGPT-4o's Initial System**

**Step 1: Inner Monologue to Develop the Scoring System**

To effectively analyze the 10 articles and create a comparative scoring system, I need to design a structure that can account for key characteristics of the articles. These characteristics might include content quality, relevance, originality, and depth. I will consider the following components:

1. **Clarity (25 points):** How clear and well-structured is the content? Articles should be easy to understand, with logical flow and organization.
2. **Depth (25 points):** How comprehensive is the analysis or discussion in the article? Articles that explore topics in detail, including nuanced perspectives, score higher.
3. **Originality (20 points):** Does the article bring unique insights, ideas, or approaches to the topic? Redundant content scores lower.
4. **Relevance (20 points):** How well does the article align with its intended purpose, topic, or audience? Relevance is key to ensuring the article meets its objectives.
5. **Presentation (10 points):** This includes formatting, readability, and overall presentation quality. Well-presented articles are easier to engage with.

**Step 2: Scoring System**

The scoring system will be based on the above components, with the following breakdown:

- **Clarity:** 0â€“25 points Clear, logical structure, minimal errors in grammar or style.
- **Depth:** 0â€“25 points Comprehensive, detailed, and insightful discussion or analysis.
- **Originality:** 0â€“20 points Unique ideas or approaches, minimal redundancy or repetition.
- **Relevance:** 0â€“20 points Strong alignment with intended purpose or audience.
- **Presentation:** 0â€“10 points High readability, proper formatting, and presentation aesthetics.

**Total Score:** Maximum of 100 points per article.

**Step 3: Scoring the Articles**

Now, I will analyze the articles based on the above scoring system, assigning scores to each, and then present the results. Please wait as I process the files.

***While it did supply the scores, they were within a markdown table that didn't copy with the rest of the response.***

I have analyzed the articles based on the scoring system and displayed the final scores for each file. If you'd like to review the scoring details or proceed with further analysis, let me know!

### System Review Prompt and Responses

```
Review the rubric, the articles, and the resulting final scores and provide your thinking, step by step, on how we can score these more appropriately.
```

#### Claude

Let me critically review my previous scoring system and results:

1. Issues with Previous Approach:
2. The scoring range (75-92) was too narrow, not reflecting significant differences between articles
3. The categories were somewhat subjective and could benefit from more concrete criteria
4. Modern relevance wasn't well-weighted despite being a key differentiator
5. The perspective on comprehensiveness didn't account for intentional focus vs length
6. The scores seemed to favor longer articles by default
7. I notice key distinguishing factors I should incorporate:
8. Treatment of primary events (Cry of Pugad Lawin, Katipunan founding, etc.)
9. Balance of biographical vs. historical context
10. Integration of contemporary significance
11. Handling of complex themes (class struggle, revolutionary ideology, etc.)
12. Citation of specific documents/works that influenced Bonifacio
13. Looking at structure more carefully:
14. Some articles use traditional chronological approach
15. Others use thematic organization
16. Need to avoid penalizing different but effective organizational strategies
17. For a revised system, I should:
18. Expand the potential scoring range
19. Create more specific, measurable criteria
20. Weight historical accuracy more heavily
21. Include evaluation of source material integration
22. Account for both depth and efficiency of coverage

Let me propose a revised scoring system:

NEW SCORING SYSTEM (200 points total):

1. Historical Content (80 points)

- Accuracy of dates and events (20)
- Proper sequencing of historical events (20)
- Integration of primary sources and influences (20)
- Treatment of key historical figures and relationships (20)
2. Analytical Depth (40 points)

- Analysis of revolutionary ideology (10)
- Treatment of class and social dynamics (10)
- Discussion of political context (10)
- Examination of historical impact (10)
3. Contemporary Relevance (40 points)

- Modern significance (20)
- Connection to present-day issues (20)
4. Structure & Clarity (40 points)

- Logical organization (10)
- Writing clarity (10)
- Effective use of examples (10)
- Balanced coverage (10)

This system should provide:

- Broader scoring range
- More objective criteria
- Better recognition of different strengths
- More nuanced evaluation of content

Let me rescore one article as a test:

AB-C-AI-OS.md: Historical Content: 75/80

- Excellent accuracy and sequencing
- Strong integration of influences
- Detailed treatment of relationships

Analytical Depth: 35/40

- Strong analysis of revolutionary ideology
- Excellent treatment of class dynamics
- Rich political context

Contemporary Relevance: 38/40

- Exceptional modern significance
- Strong present-day connections

Structure & Clarity: 37/40

- Very logical organization
- Clear writing
- Effective examples
- Well-balanced

Total: 185/200

This scoring seems to better reflect the article's strengths and provides more room for differentiation. Should I proceed with rescoring all articles using this revised system?

Would you like me to continue with the complete rescoring using this revised system? I believe it will provide more meaningful differentiation and better reflect the unique strengths and weaknesses of each article.

#### ChatGPT-4o

**Step 1: Review the Rubric**

The rubric comprises five categories: **Clarity**, **Depth**, **Originality**, **Relevance**, and **Presentation**, with a maximum total score of 100 points. The breakdown is as follows:

- **Clarity (25 points):** Evaluates how well the article communicates its ideas, structure, and logical flow.
- **Depth (25 points):** Measures the comprehensiveness and thoroughness of the discussion or analysis.
- **Originality (20 points):** Assesses whether the article provides unique insights or approaches to the topic.
- **Relevance (20 points):** Focuses on the alignment of the content with its intended purpose and audience.
- **Presentation (10 points):** Considers formatting, layout, and readability.

This rubric is reasonable for evaluating overall quality. However, I will analyze how effectively it was applied to the articles and explore potential adjustments for scoring them more appropriately.

**Step 2: Evaluation of the Articles and Scoring Issues**

Observations from the Current Scoring:

1. **Clarity and Depth:**

- Articles with slightly weaker logical flow and structure received lower Clarity scores. However, some "simpler" articles might have been overly penalized compared to more detailed ones, despite being clear.
- Depth seems to favor articles with longer discussions, potentially overshadowing succinct but impactful content.
2. **Originality:**

- The current scores reflect originality moderately well. However, distinguishing originality can sometimes require a closer contextual analysis (e.g., comparing overlap with existing knowledge).
3. **Relevance:**

- The scores align well with the relevance rubric, but articles with nuanced subtopics might require additional weighting here.
4. **Presentation:**

- Articles with polished formatting score higher here, but minor formatting issues might have overly influenced results.

**Step 3: Adjusting the Rubric for Better Scoring**

Suggestions for Improvement:

1. **Dynamic Weights for Clarity vs. Depth: **Combine **Clarity** and **Depth** into a single **Effectiveness** metric (weighted at 50 points). This adjusts for the fact that clarity and depth often overlap, and a more nuanced combination could be applied.
2. **Add Impact as a Category (15 points): **Introduce a new **Impact** category to evaluate how compelling and memorable the article is, considering both style and content.
3. **Balance Presentation Weight (10 points): **Retain Presentation at 10 points but ensure minor issues donâ€™t significantly impact scores.
4. **Reframe Relevance (25 points): **Increase the weight of Relevance to capture alignment with the intended topic, as this is a crucial metric for assessing utility.

**Revised Rubric:**

- **Effectiveness:** 50 points
- **Originality:** 20 points
- **Relevance:** 25 points
- **Presentation:** 10 points
- **Impact:** 15 points

This rubric provides a more balanced approach, aligning clarity and depth into a single, broader metric and introducing a measure of how compelling the articles are.

**Step 4: Re-scoring the Articles**

Now, Iâ€™ll apply this revised rubric to the articles and provide new scores based on this framework. Please hold while I process this.

I have recalculated the scores based on the revised rubric, which incorporates the suggested adjustments for improved accuracy and balance. The results have been displayed for review. Let me know if you need further analysis or any refinements.

<u></u>